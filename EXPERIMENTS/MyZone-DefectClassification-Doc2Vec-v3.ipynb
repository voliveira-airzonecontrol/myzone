{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# After sales text clustering using Doc2Vec\n",
    "## Enhanced corpus with more data"
   ],
   "id": "ac81325cae8c996"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:45:03.964675Z",
     "start_time": "2024-05-15T13:43:30.735294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "# nlp = spacy.load('es_core_news_md')\n",
    "# nlp = spacy.load('es_core_news_sm')\n",
    "import multiprocessing\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gensim.models.doc2vec\n",
    "\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "data_version = \"2024-05-14\"\n",
    "corpus_version = \"2024-05-15\"\n",
    "model_version = \"2024-05-15\"\n",
    "data_base_path = f\"../DATA/processed/\"\n",
    "model_base_path = f\"../MODELS/{data_version}\""
   ],
   "id": "817bd93bce229d84",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T13:45:03.980645Z",
     "start_time": "2024-05-15T13:45:03.965668Z"
    }
   },
   "source": [
    "# Function to preprocess the text\n",
    "def preprocess_text(docs):\n",
    "    # Ensure all entries are strings\n",
    "    docs = docs.fillna(\"\").astype(str)\n",
    "    # Process the text\n",
    "    texts = [doc for doc in nlp.pipe(docs, disable=[\"ner\", \"parser\"])]\n",
    "    processed_texts = []\n",
    "    for doc in texts:\n",
    "        tokens = [\n",
    "            token.text.lower()\n",
    "            for token in doc\n",
    "            if not token.is_punct and not token.is_stop and not token.is_space\n",
    "        ]\n",
    "        processed_texts.append(\" \".join(tokens))\n",
    "    return processed_texts"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:45:03.996654Z",
     "start_time": "2024-05-15T13:45:03.981645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Class Model with comments\n",
    "class CommentedDoc2Vec(Doc2Vec):\n",
    "    def __init__(self, comment=\"\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.comment = comment"
   ],
   "id": "58c74121638c9ebf",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:47:14.554115Z",
     "start_time": "2024-05-15T13:45:03.997655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load train corpus from disk\n",
    "corpus = pd.read_csv(\"../DATA/processed/2024-05-15/corpus_spanish.csv\", sep=\"¬\")\n",
    "corpus[\"text_to_analyse\"] = (\n",
    "    corpus[\"text_to_analyse\"].fillna(\"\").astype(str)\n",
    ")  # Ensure all values are strings\n",
    "corpus[\"processed_text\"] = preprocess_text(corpus[\"text_to_analyse\"])\n",
    "corpus = corpus[corpus[\"processed_text\"] != \"\"]\n",
    "# corpus = pd.read_csv(f'../DATA/processed/{corpus_version}/corpus_processed.csv', sep='¬')\n",
    "corpus.sample(10)"
   ],
   "id": "404b2ca823e64867",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:54:35.450704Z",
     "start_time": "2024-05-15T13:54:35.440183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "common_kwargs = dict(\n",
    "    vector_size=200,\n",
    "    epochs=20,\n",
    "    min_count=2,\n",
    "    sample=0,\n",
    "    workers=multiprocessing.cpu_count(),\n",
    "    negative=5,\n",
    "    hs=0,\n",
    "    seed=0,\n",
    ")"
   ],
   "id": "94d97156302aed0",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:54:35.701891Z",
     "start_time": "2024-05-15T13:54:35.694890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PV-DBOW plain\n",
    "model = CommentedDoc2Vec(\n",
    "    dm=0,\n",
    "    comment=f\"PV-DBOW-\"\n",
    "    f\"v_size {common_kwargs['vector_size']}-\"\n",
    "    f\"epochs {common_kwargs['epochs']}-\"\n",
    "    f\"hs {common_kwargs['hs']}-\"\n",
    "    f\"sample {common_kwargs['sample']}-\"\n",
    "    f\"negative {common_kwargs['negative']}-\"\n",
    "    f\"min_count {common_kwargs['min_count']}-\"\n",
    "    f\"corpus {corpus_version}\",\n",
    "    **common_kwargs,\n",
    ")"
   ],
   "id": "5a1b047ed75dcbcd",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:54:36.965134Z",
     "start_time": "2024-05-15T13:54:35.958710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create TaggedDocument objects\n",
    "tagged_data = [\n",
    "    TaggedDocument(words=doc.split(), tags=[i])\n",
    "    for i, doc in enumerate(corpus[\"processed_text\"])\n",
    "]"
   ],
   "id": "dcd0cea9fef4fce1",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:54:37.977793Z",
     "start_time": "2024-05-15T13:54:36.967137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build the vocabulary\n",
    "model.build_vocab(tagged_data)\n",
    "print(\"Model: %s : vocabulary scanned & state initialized\" % model.comment)"
   ],
   "id": "d68ee625f6c23606",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:56:02.869273Z",
     "start_time": "2024-05-15T13:54:50.912790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model using the Corpus\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "print(\"%s training completed\" % model.comment)"
   ],
   "id": "590756a610508c4d",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:45:21.722496Z",
     "start_time": "2024-05-15T10:45:21.082904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the model\n",
    "os.makedirs(model_base_path, exist_ok=True)\n",
    "model_name = (\n",
    "    f\"{model_base_path}/{type(model).__name__}_{model.comment.replace(' ', '_')}.model\"\n",
    ")\n",
    "model.save(model_name)\n",
    "print(f\"Model saved at {model_name}\")"
   ],
   "id": "89e8ce738ced365a",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load the model and the data and infer vectors",
   "id": "8c30c4f8067d777"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T12:00:00.481474Z",
     "start_time": "2024-05-15T11:59:59.443769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model\n",
    "model_name = \"../MODELS/2024-05-15/CommentedDoc2Vec_PV-DBOW-v_size_200-epochs_20-hs_0-sample_0-negative_5-min_count_2.model\"\n",
    "model = CommentedDoc2Vec.load(model_name)\n",
    "print(f\"Model {model} loaded\")"
   ],
   "id": "207b2da7f8b4257d",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:57:05.460100Z",
     "start_time": "2024-05-15T13:57:05.095011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data to analyse\n",
    "text_to_analyse_clean = pd.read_csv(\n",
    "    f\"{data_base_path}/{data_version}/text_to_analyse_clean.csv\", sep=\"¬\"\n",
    ")"
   ],
   "id": "de254ada8a6bff76",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:57:51.888544Z",
     "start_time": "2024-05-15T13:57:07.708145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Infer vectors for the text_to_analyse\n",
    "text_to_analyse_clean[\"processed_text\"] = preprocess_text(\n",
    "    text_to_analyse_clean[\"text_to_analyse\"]\n",
    ")\n",
    "text_to_analyse_clean[\"vector\"] = text_to_analyse_clean[\"processed_text\"].apply(\n",
    "    lambda x: model.infer_vector(x.split())\n",
    ")"
   ],
   "id": "18cc8863703965ad",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:57:51.935087Z",
     "start_time": "2024-05-15T13:57:51.889527Z"
    }
   },
   "cell_type": "code",
   "source": "text_to_analyse_clean.sample(10)",
   "id": "e85b0cbeb688a26d",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate the similarity between the texts",
   "id": "6d66a64ffe898e95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:57:51.951112Z",
     "start_time": "2024-05-15T13:57:51.936086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read list of errors\n",
    "errors = pd.read_csv(\"../DATA/TablaTipoErrorPostventa.csv\", sep=\";\", header=0)[\n",
    "    [\"Código\", \"CODCAR3\", \"CODCAR2\", \"DESCFAM\", \"Motivo General\", \"DESCRICION\"]\n",
    "]\n",
    "errors.columns = [\n",
    "    \"ID_ERROR\",\n",
    "    \"CODCAR3\",\n",
    "    \"CODCAR2\",\n",
    "    \"DESCFAM\",\n",
    "    \"MOTIVO\",\n",
    "    \"DESCRIPCION\",\n",
    "]  # Rename columns\n",
    "errors[\"DESCRIPCION\"] = (\n",
    "    errors[\"MOTIVO\"] + \" \" + errors[\"DESCRIPCION\"]\n",
    ")  # Concatenate MOTIVO and DESCRIPCION\n",
    "errors[\"CODCAR2\"] = errors[\"CODCAR2\"].str.replace(\"-\", \"0\").astype(int)  # Clean CODCAR2"
   ],
   "id": "ec13acedc5a090fa",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:57:52.109602Z",
     "start_time": "2024-05-15T13:57:51.953088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Infer vector for errors\n",
    "errors[\"description_processed\"] = preprocess_text(errors[\"DESCRIPCION\"])\n",
    "errors[\"vector\"] = errors[\"description_processed\"].apply(\n",
    "    lambda x: model.infer_vector(x.split())\n",
    ")"
   ],
   "id": "2c562de6658aa0df",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:57:52.140776Z",
     "start_time": "2024-05-15T13:57:52.110602Z"
    }
   },
   "cell_type": "code",
   "source": "errors",
   "id": "e74c98888c251b10",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T13:58:03.208916Z",
     "start_time": "2024-05-15T13:57:52.141778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def calculate_cosine_score(vector, vector_error):\n",
    "    return cosine_similarity(vector.reshape(1, -1), vector_error.reshape(1, -1))[0][0]\n",
    "\n",
    "\n",
    "def calculate_mean_cosine_score(vector, vector_error, n=5):\n",
    "    if vector.size == 0 or vector_error.size == 0:\n",
    "        return np.nan  # Return NaN if there's no vector to compare\n",
    "    cosine_scores = []\n",
    "    for i in range(n):\n",
    "        cosine_scores.append(calculate_cosine_score(vector, vector_error))\n",
    "    return np.mean(cosine_scores)"
   ],
   "id": "dc724db1f88a32d1",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:02:43.962665Z",
     "start_time": "2024-05-15T13:58:03.209917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the cosine similarity between the text_to_analyse and the errors\n",
    "for index, row in errors.iterrows():\n",
    "    # Create a condition for filtering\n",
    "    condition = text_to_analyse_clean[\"CAR3\"] == row[\"CODCAR3\"]\n",
    "    if row[\"CODCAR2\"]:\n",
    "        condition &= text_to_analyse_clean[\"CAR2\"] == row[\"CODCAR2\"]\n",
    "\n",
    "    if not text_to_analyse_clean.loc[condition, \"vector\"].empty:\n",
    "        text_to_analyse_clean.loc[condition, f'cosine_similarity_{row[\"ID_ERROR\"]}'] = (\n",
    "            text_to_analyse_clean.loc[condition, \"vector\"].apply(\n",
    "                lambda x: calculate_mean_cosine_score(x, row[\"vector\"])\n",
    "            )\n",
    "        )\n",
    "\n",
    "    print(f\"Error {row['ID_ERROR']} calculated\")"
   ],
   "id": "3a91f05ef3c100a7",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:02:43.992667Z",
     "start_time": "2024-05-15T14:02:43.963633Z"
    }
   },
   "cell_type": "code",
   "source": "text_to_analyse_clean.sample(10)",
   "id": "628add2ca2d52d9d",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save text_to_analyse to disk\n",
    "# text_to_analyse_clean.to_csv(f\"{data_base_path}/text_to_analyse_with_errors.csv\", sep='¬', encoding='utf-8-sig', index=False)"
   ],
   "id": "53848039156e5a30",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load text_to_analyse from disk\n",
    "# text_to_analyse_clean = pd.read_csv(f\"{data_base_path}/text_to_analyse_with_errors.csv\", sep='¬', encoding='utf-8-sig')"
   ],
   "id": "11dcc448408227d2",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:02:44.054516Z",
     "start_time": "2024-05-15T14:02:43.993639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cosine_columns = [\n",
    "    col for col in text_to_analyse_clean.columns if \"cosine_similarity_\" in col\n",
    "]\n",
    "text_to_analyse_clean[cosine_columns] = text_to_analyse_clean[cosine_columns].fillna(\n",
    "    0\n",
    ")  # Fill NA with 0\n",
    "text_to_analyse_clean.loc[:, \"highest_score\"] = text_to_analyse_clean[\n",
    "    cosine_columns\n",
    "].max(axis=1)\n",
    "text_to_analyse_clean.loc[:, \"highest_score_error\"] = (\n",
    "    text_to_analyse_clean[cosine_columns]\n",
    "    .idxmax(axis=1)\n",
    "    .apply(lambda x: x.split(\"_\")[-1])\n",
    ")"
   ],
   "id": "41b91f6e7c79e4ba",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:02:44.085023Z",
     "start_time": "2024-05-15T14:02:44.056514Z"
    }
   },
   "cell_type": "code",
   "source": "text_to_analyse_clean.head(10)",
   "id": "98fd54a30177f265",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:02:44.165029Z",
     "start_time": "2024-05-15T14:02:44.086024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "top10_per_error = (\n",
    "    text_to_analyse_clean[\n",
    "        [\"codigo\", \"text_to_analyse\", \"highest_score\", \"highest_score_error\"]\n",
    "    ]\n",
    "    .groupby(\"highest_score_error\", group_keys=False)\n",
    "    .apply(lambda x: x.nlargest(10, \"highest_score\"))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "top10_per_error.head(500)"
   ],
   "id": "6718f6201e738b1c",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T14:02:44.180996Z",
     "start_time": "2024-05-15T14:02:44.166031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_to_analyse_clean[text_to_analyse_clean[\"codigo\"] == \"MMHSNG1V2C\"][\n",
    "    [\"codigo\", \"text_to_analyse\", \"highest_score\", \"highest_score_error\"]\n",
    "]"
   ],
   "id": "3ddc0d705a434582",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " ## Visualize the results",
   "id": "d918672fc489b4b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:59:41.732165Z",
     "start_time": "2024-05-15T10:59:41.718169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = text_to_analyse_clean[[\"vector\", \"highest_score_error\"]]\n",
    "# Convert string representations of lists to actual numpy arrays\n",
    "results[\"vector\"] = results[\"vector\"].apply(\n",
    "    lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \") if isinstance(x, str) else x\n",
    ")"
   ],
   "id": "aefe967281e0add2",
   "execution_count": 45,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:59:50.726821Z",
     "start_time": "2024-05-15T10:59:47.807558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Expand each vector into its own column\n",
    "expanded_vectors = results[\"vector\"].apply(pd.Series)\n",
    "expanded_vectors.columns = [f\"vector_{i}\" for i in range(expanded_vectors.shape[1])]\n",
    "results = pd.concat([results, expanded_vectors], axis=1)"
   ],
   "id": "2cdcd1d73abecbb4",
   "execution_count": 46,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:59:52.529011Z",
     "start_time": "2024-05-15T10:59:52.498505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = results.drop([\"vector\", \"highest_score_error\"], axis=1)\n",
    "y = pd.to_numeric(results[\"highest_score_error\"], errors=\"coerce\")"
   ],
   "id": "4a0847c959f56ca0",
   "execution_count": 47,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T11:01:30.152724Z",
     "start_time": "2024-05-15T10:59:56.530914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "X_tsne = tsne.fit_transform(X)"
   ],
   "id": "9cb70ddbc168898",
   "execution_count": 48,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T11:01:31.810231Z",
     "start_time": "2024-05-15T11:01:30.944997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap=\"tab20\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ],
   "id": "1d2cc7ec1d723f0a",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T11:05:25.668666Z",
     "start_time": "2024-05-15T11:01:31.811200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create TSNE with 3 components\n",
    "tsne = TSNE(n_components=3, random_state=0)\n",
    "X_tsne_3d = tsne.fit_transform(X)"
   ],
   "id": "349f64eaf96fac3",
   "execution_count": 51,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T11:05:29.166282Z",
     "start_time": "2024-05-15T11:05:25.669666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plot data in 3D\n",
    "%matplotlib qt6\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "scatter = ax.scatter(\n",
    "    X_tsne_3d[:, 0], X_tsne_3d[:, 1], X_tsne_3d[:, 2], c=y, cmap=\"tab20\"\n",
    ")\n",
    "# Add legend\n",
    "plt.legend(*scatter.legend_elements(num=10), title=\"Classes\")\n",
    "plt.show()"
   ],
   "id": "c303e6f75e55dfcd",
   "execution_count": 52,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "5ed89a9422d69cfd",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
