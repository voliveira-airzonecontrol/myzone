{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:03:01.403513Z",
     "start_time": "2024-05-15T08:02:58.655703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import date\n",
    "import os\n",
    "import spacy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "TRAINING_DATA_PATH = '..\\\\..\\\\Datos - Myzone\\\\TrainningData'"
   ],
   "id": "bb3ba349b807fc8b",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Incidencias MyZone",
   "id": "d9a2a03c2107a8b0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T08:05:23.894095Z",
     "start_time": "2024-05-15T08:05:23.885578Z"
    }
   },
   "source": [
    "def query_data(query):\n",
    "    \"\"\"\n",
    "    Function to query data from the database using sqlalchemy\n",
    "    :param query: \n",
    "    :return: pd.DataFrame\n",
    "    \n",
    "    Connection parameters:\n",
    "    user = readmyzone\n",
    "    password = (get from environment variable MYSQL_PASSWORD)\n",
    "    host = 192.168.2.7\n",
    "    port = 3306\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the connection string\n",
    "    user = 'readmyzone'\n",
    "    password = os.environ.get('MYSQL_PASSWORD')\n",
    "    host = '192.168.2.7'\n",
    "    port = '3306'\n",
    "    db = 'myzone'\n",
    "    connection_string = f'mysql+pymysql://{user}:{password}@{host}:{port}/{db}'\n",
    "    \n",
    "    # Create the engine\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    try:\n",
    "        # Query the data\n",
    "        data = pd.read_sql(query, engine)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        data = None\n",
    "    \n",
    "    return data"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:05:28.594071Z",
     "start_time": "2024-05-15T08:05:24.241634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sav_incidencias = query_data('SELECT * FROM sav_incidencias')\n",
    "sav_piezas = query_data('SELECT * FROM sav_piezas')\n",
    "sav_estados = query_data('SELECT * FROM sav_estados')\n",
    "sav_incidencias_tipo = query_data('SELECT * FROM sav_incidencias_tipo')"
   ],
   "id": "299c5edf75cf4a3a",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:05:30.420972Z",
     "start_time": "2024-05-15T08:05:30.020617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = sav_incidencias.merge(sav_piezas, left_on='codigo', right_on='codigo_incidencia', how='left', suffixes=(None, '_pieza'))\n",
    "dataset = dataset.merge(sav_estados, left_on='estado', right_on='id', how='left', suffixes=(None, '_estado'))\n",
    "dataset = dataset.merge(sav_incidencias_tipo, left_on='tipo', right_on='id', how='left', suffixes=(None, '_tipo'))"
   ],
   "id": "7f168c757e8541f4",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:05:31.425060Z",
     "start_time": "2024-05-15T08:05:30.615808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset['modification_date'] = pd.to_datetime(dataset['modification_date'], errors='coerce')\n",
    "clean_dataset = dataset[(dataset[\"tipo\"] == 1) & (dataset[\"estado\"].isin([2,6])) & (dataset['modification_date'] < '2024-05-09')]"
   ],
   "id": "662369274c4eef79",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:05:31.819589Z",
     "start_time": "2024-05-15T08:05:31.583289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load from disk the text to translate dictionary\n",
    "fields_to_translate = [\"desc_problema\", \"problema\", \"descripcion\"]\n",
    "text_to_translate = {}\n",
    "for text in fields_to_translate:\n",
    "    text_to_translate[text] = pd.read_csv(f\"../DATA/{text}.csv\", sep='¬', encoding='utf-8-sig')"
   ],
   "id": "61fd99840892d3ae",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:05:32.608065Z",
     "start_time": "2024-05-15T08:05:32.463624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "desc_problema_translated = pd.read_csv(\"../DATA/desc_problema_translated.csv\", sep='¬', encoding='utf-8-sig', engine='python')\n",
    "descripcion_translated = pd.read_csv(\"../DATA/descripcion_translated.csv\", sep='¬', encoding='utf-8-sig', engine='python')\n",
    "problema_translated = pd.read_csv(\"../DATA/problema_translated.csv\", sep='¬', encoding='utf-8-sig', engine='python')# Data preprocessing (Merging the translated text)"
   ],
   "id": "52d27e45c2bd93b7",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:05:33.015360Z",
     "start_time": "2024-05-15T08:05:32.989801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Delete rows with values (desc_problema, desc_problema_translated)\n",
    "desc_problema_translated = desc_problema_translated[~desc_problema_translated[\"desc_problema_translated\"].isin([\"desc_problema_translated\"])]\n",
    "descripcion_translated = descripcion_translated[~descripcion_translated[\"descripcion_translated\"].isin([\"descripcion_translated\"])]\n",
    "problema_translated = problema_translated[~problema_translated[\"problema_translated\"].isin([\"problema_translated\"])]"
   ],
   "id": "37c2746325418e8d",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:05:34.519109Z",
     "start_time": "2024-05-15T08:05:34.470482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge the translated text with the text_to_translate dataframe\n",
    "desc_problema_translated = text_to_translate[\"desc_problema\"].merge(desc_problema_translated, left_on=\"desc_problema\", right_on=\"desc_problema\", how=\"left\")\n",
    "descripcion_translated = text_to_translate[\"descripcion\"].merge(descripcion_translated, left_on=\"descripcion\", right_on=\"descripcion\", how=\"left\")\n",
    "problema_translated = text_to_translate[\"problema\"].merge(problema_translated, left_on=\"problema\", right_on=\"problema\", how=\"left\")"
   ],
   "id": "b4c2c46137c0ff8",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:05:34.721336Z",
     "start_time": "2024-05-15T08:05:34.700532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fill NA with the original texts\n",
    "desc_problema_translated.fillna({\"desc_problema_translated\": desc_problema_translated[\"desc_problema\"]}, inplace=True)\n",
    "descripcion_translated.fillna({\"descripcion_translated\": descripcion_translated[\"descripcion\"]}, inplace=True)\n",
    "problema_translated.fillna({\"problema_translated\": problema_translated[\"problema\"]}, inplace=True)"
   ],
   "id": "433840134921e06c",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:05:35.253814Z",
     "start_time": "2024-05-15T08:05:34.936304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge the translated text with the original dataset\n",
    "clean_dataset = clean_dataset.merge(desc_problema_translated, left_on=\"desc_problema\", right_on=\"desc_problema\", how=\"left\")\n",
    "clean_dataset = clean_dataset.merge(descripcion_translated, left_on=\"descripcion\", right_on=\"descripcion\", how=\"left\")\n",
    "clean_dataset = clean_dataset.merge(problema_translated, left_on=\"problema\", right_on=\"problema\", how=\"left\")"
   ],
   "id": "15bf515a1aac0ed8",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:05:35.472754Z",
     "start_time": "2024-05-15T08:05:35.427485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get only the columns with the fields of interest\n",
    "incidencias = clean_dataset[['codigo','id_pieza','desc_problema_translated','descripcion_translated','problema_translated','cod_articulo']]\n",
    "# Fill NA with empty string\n",
    "incidencias.fillna(\"\", inplace=True)"
   ],
   "id": "a19c4dbd8a0f0008",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:05:36.181652Z",
     "start_time": "2024-05-15T08:05:36.127529Z"
    }
   },
   "cell_type": "code",
   "source": "incidencias.loc[:, 'text_to_analyse'] = incidencias['desc_problema_translated'] + ' ' + incidencias['descripcion_translated'] + ' ' + incidencias['problema_translated'] + ' ' + incidencias['cod_articulo']",
   "id": "c1526fbea6ec4c60",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:05:37.385550Z",
     "start_time": "2024-05-15T08:05:37.364446Z"
    }
   },
   "cell_type": "code",
   "source": "incidencias = incidencias[['text_to_analyse']]",
   "id": "59675def9333e9ff",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FAQ",
   "id": "d5d0d1f261cbeeb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:06:00.657159Z",
     "start_time": "2024-05-15T08:05:40.558215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "faq_path = os.path.join(TRAINING_DATA_PATH, 'FAQ.csv')\n",
    "faq = pd.read_csv(faq_path, sep=\";\", header=None)\n",
    "faq.columns = ['text_to_analyse']"
   ],
   "id": "284268d7cc71ed09",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:06:00.830900Z",
     "start_time": "2024-05-15T08:06:00.659161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove html tags\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "faq['text_to_analyse'] = faq['text_to_analyse'].apply(remove_html_tags)"
   ],
   "id": "9597e2543169e64e",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Products documentation",
   "id": "423daeb26aecb36a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T09:04:48.873935Z",
     "start_time": "2024-05-15T09:04:48.863423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "product_documentation_path = r\"\\\\central4\\Publica\\Product_technical_documentation-Documentación_técnica_producto\"\n",
    "\n",
    "def get_pdf_files(path):\n",
    "    pdf_files = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith('.pdf'):\n",
    "                pdf_files.append(os.path.join(root, file))\n",
    "    return pdf_files\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = []\n",
    "    sentences = []\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf = PyPDF2.PdfReader(file)\n",
    "            for page in range(len(pdf.pages)):\n",
    "                text.append(pdf.pages[page].extract_text())\n",
    "                \n",
    "        for i, page in enumerate(text):\n",
    "            doc = nlp(page)\n",
    "            for sentence in doc.sents:\n",
    "                sentences.append(sentence.text)\n",
    "    except Exception as e:\n",
    "        print(f'Error processing {pdf_path}: {e}')\n",
    "        raise e\n",
    "    \n",
    "    return pd.DataFrame(sentences, columns=['text_to_analyse'])"
   ],
   "id": "5ee912290f0322fd",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:02:35.980139Z",
     "start_time": "2024-05-15T09:04:50.751019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm # Progress bar\n",
    "\n",
    "pdfs = get_pdf_files(product_documentation_path)\n",
    "product_documentation = pd.DataFrame()\n",
    "\n",
    "def process_pdf(pdf):\n",
    "    #print(f'Processing {pdf}')\n",
    "    try:\n",
    "        df = extract_text_from_pdf(pdf)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Process the PDF files in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Map the process_pdf function to all the PDF files\n",
    "    results = list(tqdm(executor.map(process_pdf, pdfs), total=len(pdfs)))\n",
    "    \n",
    "    # Concatenate results as they complete\n",
    "    for result in results:\n",
    "        product_documentation = pd.concat([product_documentation, result])\n",
    "\n",
    "\"\"\"for pdf in pdfs:\n",
    "    print(f'Processing {pdf}')\n",
    "    text = extract_text_from_pdf(pdf)\n",
    "    product_documentation = pd.concat([product_documentation, text])\"\"\""
   ],
   "id": "703f1b6b2e990605",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:02:36.137505Z",
     "start_time": "2024-05-15T10:02:35.982139Z"
    }
   },
   "cell_type": "code",
   "source": "product_documentation",
   "id": "9774de86f0f9b5",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Catalogo de productos",
   "id": "ce4c8feb25408908"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:03:09.682095Z",
     "start_time": "2024-05-15T10:03:03.686302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "catalogo_path = os.path.join(TRAINING_DATA_PATH, 'catalogo.pdf')\n",
    "catalogo = extract_text_from_pdf(catalogo_path)"
   ],
   "id": "152bc36dd60b9ba5",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Join all the data",
   "id": "1ca87b0b8514f5bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:03:15.279680Z",
     "start_time": "2024-05-15T10:03:15.240702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus = pd.concat([incidencias, faq, catalogo, product_documentation])\n",
    "print(f'Corpus shape: {corpus.shape}')"
   ],
   "id": "ca2b23f8f055844a",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:03:27.160546Z",
     "start_time": "2024-05-15T10:03:27.125517Z"
    }
   },
   "cell_type": "code",
   "source": "corpus.sample(10)",
   "id": "3fcc9283a732cc68",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:05:09.487500Z",
     "start_time": "2024-05-15T10:05:06.845286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the corpus to disk\n",
    "today_date = date.today().isoformat()\n",
    "data_base_path = f\"../DATA/processed/{today_date}\"\n",
    "os.makedirs(data_base_path, exist_ok=True)\n",
    "corpus.to_csv(f\"{data_base_path}/corpus.csv\", sep='¬', index=False)"
   ],
   "id": "edacfdc8b3daeecf",
   "execution_count": 33,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
