{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:05:40.895161Z",
     "start_time": "2024-11-14T12:05:34.562992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import date\n",
    "import os\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "TRAINING_DATA_PATH = \"..\\\\..\\\\Datos - Myzone\\\\TrainningData\""
   ],
   "id": "bb3ba349b807fc8b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Incidencias MyZone",
   "id": "d9a2a03c2107a8b0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-14T12:05:44.424795Z",
     "start_time": "2024-11-14T12:05:44.406768Z"
    }
   },
   "source": [
    "def query_data(query):\n",
    "    \"\"\"\n",
    "    Function to query data from the database using sqlalchemy\n",
    "    :param query:\n",
    "    :return: pd.DataFrame\n",
    "\n",
    "    Connection parameters:\n",
    "    user = readmyzone\n",
    "    password = (get from environment variable MYSQL_PASSWORD)\n",
    "    host = 192.168.2.7\n",
    "    port = 3306\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the connection string\n",
    "    user = \"readmyzone\"\n",
    "    password = os.environ.get(\"MYSQL_PASSWORD\")\n",
    "    host = \"192.168.2.7\"\n",
    "    port = \"3306\"\n",
    "    db = \"myzone\"\n",
    "    connection_string = f\"mysql+pymysql://{user}:{password}@{host}:{port}/{db}\"\n",
    "\n",
    "    # Create the engine\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    try:\n",
    "        # Query the data\n",
    "        data = pd.read_sql(query, engine)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        data = None\n",
    "\n",
    "    return data"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:05:52.086717Z",
     "start_time": "2024-11-14T12:05:46.423961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sav_incidencias = query_data(\"SELECT * FROM sav_incidencias\")\n",
    "sav_piezas = query_data(\"SELECT * FROM sav_piezas\")\n",
    "sav_estados = query_data(\"SELECT * FROM sav_estados\")\n",
    "sav_incidencias_tipo = query_data(\"SELECT * FROM sav_incidencias_tipo\")"
   ],
   "id": "299c5edf75cf4a3a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:06:00.457635Z",
     "start_time": "2024-11-14T12:05:59.664721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = sav_incidencias.merge(\n",
    "    sav_piezas,\n",
    "    left_on=\"codigo\",\n",
    "    right_on=\"codigo_incidencia\",\n",
    "    how=\"left\",\n",
    "    suffixes=(None, \"_pieza\"),\n",
    ")\n",
    "dataset = dataset.merge(\n",
    "    sav_estados, left_on=\"estado\", right_on=\"id\", how=\"left\", suffixes=(None, \"_estado\")\n",
    ")\n",
    "dataset = dataset.merge(\n",
    "    sav_incidencias_tipo,\n",
    "    left_on=\"tipo\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(None, \"_tipo\"),\n",
    ")"
   ],
   "id": "7f168c757e8541f4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:06:02.254536Z",
     "start_time": "2024-11-14T12:06:01.436908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset[\"modification_date\"] = pd.to_datetime(\n",
    "    dataset[\"modification_date\"], errors=\"coerce\"\n",
    ")\n",
    "clean_dataset = dataset[\n",
    "    (dataset[\"tipo\"] == 1)\n",
    "    & (dataset[\"estado\"].isin([2, 6]))\n",
    "    & (dataset[\"modification_date\"] < \"2024-05-09\")\n",
    "]"
   ],
   "id": "662369274c4eef79",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:06:03.484624Z",
     "start_time": "2024-11-14T12:06:03.312185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load from disk the text to translate dictionary\n",
    "fields_to_translate = [\"desc_problema\", \"problema\", \"descripcion\"]\n",
    "text_to_translate = {}\n",
    "for text in fields_to_translate:\n",
    "    text_to_translate[text] = pd.read_csv(\n",
    "        f\"../DATA/{text}.csv\", sep=\"¬\", encoding=\"utf-8-sig\"\n",
    "    )"
   ],
   "id": "61fd99840892d3ae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\voliveira\\AppData\\Local\\Temp\\ipykernel_26284\\1709896185.py:5: ParserWarning: Falling back to the 'python' engine because the separator encoded in utf-8 is > 1 char long, and the 'c' engine does not support such separators; you can avoid this warning by specifying engine='python'.\n",
      "  text_to_translate[text] = pd.read_csv(\n",
      "C:\\Users\\voliveira\\AppData\\Local\\Temp\\ipykernel_26284\\1709896185.py:5: ParserWarning: Falling back to the 'python' engine because the separator encoded in utf-8 is > 1 char long, and the 'c' engine does not support such separators; you can avoid this warning by specifying engine='python'.\n",
      "  text_to_translate[text] = pd.read_csv(\n",
      "C:\\Users\\voliveira\\AppData\\Local\\Temp\\ipykernel_26284\\1709896185.py:5: ParserWarning: Falling back to the 'python' engine because the separator encoded in utf-8 is > 1 char long, and the 'c' engine does not support such separators; you can avoid this warning by specifying engine='python'.\n",
      "  text_to_translate[text] = pd.read_csv(\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:06:07.714955Z",
     "start_time": "2024-11-14T12:06:07.495794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "desc_problema_translated = pd.read_csv(\n",
    "    \"../DATA/desc_problema_translated.csv\",\n",
    "    sep=\"¬\",\n",
    "    encoding=\"utf-8-sig\",\n",
    "    engine=\"python\",\n",
    ")\n",
    "descripcion_translated = pd.read_csv(\n",
    "    \"../DATA/descripcion_translated.csv\", sep=\"¬\", encoding=\"utf-8-sig\", engine=\"python\"\n",
    ")\n",
    "problema_translated = pd.read_csv(\n",
    "    \"../DATA/problema_translated.csv\", sep=\"¬\", encoding=\"utf-8-sig\", engine=\"python\"\n",
    ")  # Data preprocessing (Merging the translated text)"
   ],
   "id": "52d27e45c2bd93b7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:06:09.063790Z",
     "start_time": "2024-11-14T12:06:09.048197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Delete rows with values (desc_problema, desc_problema_translated)\n",
    "desc_problema_translated = desc_problema_translated[\n",
    "    ~desc_problema_translated[\"desc_problema_translated\"].isin(\n",
    "        [\"desc_problema_translated\"]\n",
    "    )\n",
    "]\n",
    "descripcion_translated = descripcion_translated[\n",
    "    ~descripcion_translated[\"descripcion_translated\"].isin([\"descripcion_translated\"])\n",
    "]\n",
    "problema_translated = problema_translated[\n",
    "    ~problema_translated[\"problema_translated\"].isin([\"problema_translated\"])\n",
    "]"
   ],
   "id": "37c2746325418e8d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:06:10.357289Z",
     "start_time": "2024-11-14T12:06:10.310489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge the translated text with the text_to_translate dataframe\n",
    "desc_problema_translated = text_to_translate[\"desc_problema\"].merge(\n",
    "    desc_problema_translated,\n",
    "    left_on=\"desc_problema\",\n",
    "    right_on=\"desc_problema\",\n",
    "    how=\"left\",\n",
    ")\n",
    "descripcion_translated = text_to_translate[\"descripcion\"].merge(\n",
    "    descripcion_translated, left_on=\"descripcion\", right_on=\"descripcion\", how=\"left\"\n",
    ")\n",
    "problema_translated = text_to_translate[\"problema\"].merge(\n",
    "    problema_translated, left_on=\"problema\", right_on=\"problema\", how=\"left\"\n",
    ")"
   ],
   "id": "b4c2c46137c0ff8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:06:11.205036Z",
     "start_time": "2024-11-14T12:06:11.177581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fill NA with the original texts\n",
    "desc_problema_translated.fillna(\n",
    "    {\"desc_problema_translated\": desc_problema_translated[\"desc_problema\"]},\n",
    "    inplace=True,\n",
    ")\n",
    "descripcion_translated.fillna(\n",
    "    {\"descripcion_translated\": descripcion_translated[\"descripcion\"]}, inplace=True\n",
    ")\n",
    "problema_translated.fillna(\n",
    "    {\"problema_translated\": problema_translated[\"problema\"]}, inplace=True\n",
    ")"
   ],
   "id": "433840134921e06c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:06:12.555144Z",
     "start_time": "2024-11-14T12:06:12.260001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge the translated text with the original dataset\n",
    "clean_dataset = clean_dataset.merge(\n",
    "    desc_problema_translated,\n",
    "    left_on=\"desc_problema\",\n",
    "    right_on=\"desc_problema\",\n",
    "    how=\"left\",\n",
    ")\n",
    "clean_dataset = clean_dataset.merge(\n",
    "    descripcion_translated, left_on=\"descripcion\", right_on=\"descripcion\", how=\"left\"\n",
    ")\n",
    "clean_dataset = clean_dataset.merge(\n",
    "    problema_translated, left_on=\"problema\", right_on=\"problema\", how=\"left\"\n",
    ")"
   ],
   "id": "15bf515a1aac0ed8",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:06:14.071775Z",
     "start_time": "2024-11-14T12:06:14.031358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get only the columns with the fields of interest\n",
    "incidencias = clean_dataset[\n",
    "    [\n",
    "        \"codigo\",\n",
    "        \"id_pieza\",\n",
    "        \"desc_problema_translated\",\n",
    "        \"descripcion_translated\",\n",
    "        \"problema_translated\",\n",
    "        \"cod_articulo\",\n",
    "    ]\n",
    "]\n",
    "# Fill NA with empty string\n",
    "incidencias.fillna(\"\", inplace=True)"
   ],
   "id": "a19c4dbd8a0f0008",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\voliveira\\AppData\\Local\\Temp\\ipykernel_26284\\1726854061.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  incidencias.fillna(\"\", inplace=True)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:06:19.289902Z",
     "start_time": "2024-11-14T12:06:19.226958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "incidencias.loc[:, \"text_to_analyse\"] = (\n",
    "    incidencias[\"desc_problema_translated\"]\n",
    "    + \" \"\n",
    "    + incidencias[\"descripcion_translated\"]\n",
    "    + \" \"\n",
    "    + incidencias[\"problema_translated\"]\n",
    "    + \" \"\n",
    "    + incidencias[\"cod_articulo\"]\n",
    ")"
   ],
   "id": "c1526fbea6ec4c60",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:06:20.382083Z",
     "start_time": "2024-11-14T12:06:20.366458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "incidencias = incidencias[[\"text_to_analyse\"]]"
   ],
   "id": "59675def9333e9ff",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FAQ",
   "id": "d5d0d1f261cbeeb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:06:22.842874Z",
     "start_time": "2024-11-14T12:06:22.811626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "faq_path = os.path.join(TRAINING_DATA_PATH, \"FAQ.csv\")\n",
    "faq = pd.read_csv(faq_path, sep=\";\", header=None)\n",
    "faq.columns = [\"text_to_analyse\"]"
   ],
   "id": "284268d7cc71ed09",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:06:23.618815Z",
     "start_time": "2024-11-14T12:06:23.508937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove html tags\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "\n",
    "faq[\"text_to_analyse\"] = faq[\"text_to_analyse\"].apply(remove_html_tags)"
   ],
   "id": "9597e2543169e64e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\voliveira\\AppData\\Local\\Temp\\ipykernel_26284\\2276819301.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Products documentation",
   "id": "423daeb26aecb36a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:06:25.466260Z",
     "start_time": "2024-11-14T12:06:25.455075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "product_documentation_path = (\n",
    "    r\"\\\\central4\\Publica\\Product_technical_documentation-Documentación_técnica_producto\"\n",
    ")\n",
    "\n",
    "\n",
    "def get_pdf_files(path):\n",
    "    pdf_files = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                pdf_files.append(os.path.join(root, file))\n",
    "    return pdf_files\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = []\n",
    "    sentences = []\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            pdf = PyPDF2.PdfReader(file)\n",
    "            for page in range(len(pdf.pages)):\n",
    "                text.append(pdf.pages[page].extract_text())\n",
    "\n",
    "        for i, page in enumerate(text):\n",
    "            doc = nlp(page)\n",
    "            for sentence in doc.sents:\n",
    "                sentences.append(sentence.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path}: {e}\")\n",
    "        raise e\n",
    "\n",
    "    return pd.DataFrame(sentences, columns=[\"text_to_analyse\"])"
   ],
   "id": "5ee912290f0322fd",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-14T12:06:26.610971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "pdfs = get_pdf_files(product_documentation_path)\n",
    "product_documentation = pd.DataFrame()\n",
    "\n",
    "\n",
    "def process_pdf(pdf):\n",
    "    # print(f'Processing {pdf}')\n",
    "    try:\n",
    "        df = extract_text_from_pdf(pdf)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# Process the PDF files in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # Map the process_pdf function to all the PDF files\n",
    "    results = list(tqdm(executor.map(process_pdf, pdfs), total=len(pdfs)))\n",
    "\n",
    "    # Concatenate results as they complete\n",
    "    for result in results:\n",
    "        product_documentation = pd.concat([product_documentation, result])\n",
    "\n",
    "\"\"\"for pdf in pdfs:\n",
    "    print(f'Processing {pdf}')\n",
    "    text = extract_text_from_pdf(pdf)\n",
    "    product_documentation = pd.concat([product_documentation, text])\"\"\""
   ],
   "id": "703f1b6b2e990605",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 356/3444 [02:20<4:23:55,  5.13s/it]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "product_documentation",
   "id": "9774de86f0f9b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Catalogo de productos",
   "id": "ce4c8feb25408908"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:03:09.682095Z",
     "start_time": "2024-05-15T10:03:03.686302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "catalogo_path = os.path.join(TRAINING_DATA_PATH, \"catalogo.pdf\")\n",
    "catalogo = extract_text_from_pdf(catalogo_path)"
   ],
   "id": "152bc36dd60b9ba5",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Join all the data",
   "id": "1ca87b0b8514f5bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T10:25:17.505573Z",
     "start_time": "2024-05-23T10:25:16.873830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus = pd.concat([incidencias, faq, catalogo, product_documentation])\n",
    "print(f\"Corpus shape: {corpus.shape}\")"
   ],
   "id": "ca2b23f8f055844a",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:03:27.160546Z",
     "start_time": "2024-05-15T10:03:27.125517Z"
    }
   },
   "cell_type": "code",
   "source": "corpus.sample(10)",
   "id": "3fcc9283a732cc68",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T10:05:09.487500Z",
     "start_time": "2024-05-15T10:05:06.845286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the corpus to disk\n",
    "today_date = date.today().isoformat()\n",
    "data_base_path = f\"../DATA/processed/{today_date}\"\n",
    "os.makedirs(data_base_path, exist_ok=True)\n",
    "corpus.to_csv(f\"{data_base_path}/corpus.csv\", sep=\"¬\", index=False)"
   ],
   "id": "edacfdc8b3daeecf",
   "execution_count": 33,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
