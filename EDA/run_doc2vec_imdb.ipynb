{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\nHow to reproduce the doc2vec 'Paragraph Vector' paper\n=====================================================\n\nShows how to reproduce results of the \"Distributed Representation of Sentences and Documents\" paper by Le and Mikolov using Gensim.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:06:24.776550Z",
     "start_time": "2024-05-07T14:06:24.772199Z"
    }
   },
   "source": [
    "import logging\nlogging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n------------\n\nThis guide shows you how to reproduce the results of the paper by `Le and\nMikolov 2014 <https://arxiv.org/pdf/1405.4053.pdf>`_ using Gensim. While the\nentire paper is worth reading (it's only 9 pages), we will be focusing on\nSection 3.2: \"Beyond One Sentence - Sentiment Analysis with the IMDB\ndataset\".\n\nThis guide follows the following steps:\n\n#. Load the IMDB dataset\n#. Train a variety of Doc2Vec models on the dataset\n#. Evaluate the performance of each model using a logistic regression\n#. Examine some of the results directly:\n\nWhen examining results, we will look for answers for the following questions:\n\n#. Are inferred vectors close to the precalculated ones?\n#. Do close documents seem more related than distant ones?\n#. Do the word vectors show useful similarities?\n#. Are the word vectors from this dataset any good at analogies?\n\nLoad corpus\n-----------\n\nOur data for the tutorial will be the `IMDB archive\n<http://ai.stanford.edu/~amaas/data/sentiment/>`_.\nIf you're not familiar with this dataset, then here's a brief intro: it\ncontains several thousand movie reviews.\n\nEach review is a single line of text containing multiple sentences, for example:\n\n```\nOne of the best movie-dramas I have ever seen. We do a lot of acting in the\nchurch and this is one that can be used as a resource that highlights all the\ngood things that actors can do in their work. I highly recommend this one,\nespecially for those who have an interest in acting, as a \"must see.\"\n```\n\nThese reviews will be the **documents** that we will work with in this tutorial.\nThere are 100 thousand reviews in total.\n\n#. 25k reviews for training (12.5k positive, 12.5k negative)\n#. 25k reviews for testing (12.5k positive, 12.5k negative)\n#. 50k unlabeled reviews\n\nOut of 100k reviews, 50k have a label: either positive (the reviewer liked\nthe movie) or negative.\nThe remaining 50k are unlabeled.\n\nOur first task will be to prepare the dataset.\n\nMore specifically, we will:\n\n#. Download the tar.gz file (it's only 84MB, so this shouldn't take too long)\n#. Unpack it and extract each movie review\n#. Split the reviews into training and test datasets\n\nFirst, let's define a convenient datatype for holding data for a single document:\n\n* words: The text of the document, as a ``list`` of words.\n* tags: Used to keep the index of the document in the entire dataset.\n* split: one of ``train``\\ , ``test`` or ``extra``. Determines how the document will be used (for training, testing, etc).\n* sentiment: either 1 (positive), 0 (negative) or None (unlabeled document).\n\nThis data type is helpful for later evaluation and reporting.\nIn particular, the ``index`` member will help us quickly and easily retrieve the vectors for a document from a model.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:06:29.182874Z",
     "start_time": "2024-05-07T14:06:29.177654Z"
    }
   },
   "source": [
    "import collections\n\nSentimentDocument = collections.namedtuple('SentimentDocument', 'words tags split sentiment')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now proceed with loading the corpus.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:09:03.607539Z",
     "start_time": "2024-05-07T14:07:59.049156Z"
    }
   },
   "source": [
    "import io\n",
    "import re\n",
    "import tarfile\n",
    "import os.path\n",
    "\n",
    "import smart_open\n",
    "import gensim.utils\n",
    "\n",
    "def download_dataset(url='http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'):\n",
    "    fname = url.split('/')[-1]\n",
    "\n",
    "    if os.path.isfile(fname):\n",
    "       return fname\n",
    "\n",
    "    # Download the file to local storage first.\n",
    "    with smart_open.open(url, \"rb\") as fin:\n",
    "        with smart_open.open(fname, 'wb') as fout:\n",
    "            while True:\n",
    "                buf = fin.read(io.DEFAULT_BUFFER_SIZE)\n",
    "                if not buf:\n",
    "                    break\n",
    "                fout.write(buf)\n",
    "\n",
    "    return fname\n",
    "\n",
    "def create_sentiment_document(name, text, index):\n",
    "    _, split, sentiment_str, _ = name.split('/')\n",
    "    sentiment = {'pos': 1.0, 'neg': 0.0, 'unsup': None}[sentiment_str]\n",
    "\n",
    "    if sentiment is None:\n",
    "        split = 'extra'\n",
    "\n",
    "    tokens = gensim.utils.to_unicode(text).split()\n",
    "    return SentimentDocument(tokens, [index], split, sentiment)\n",
    "\n",
    "def extract_documents():\n",
    "    fname = download_dataset()\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    with tarfile.open(fname, mode='r:gz') as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if re.match(r'aclImdb/(train|test)/(pos|neg|unsup)/\\d+_\\d+.txt$', member.name):\n",
    "                member_bytes = tar.extractfile(member).read()\n",
    "                member_text = member_bytes.decode('utf-8', errors='replace')\n",
    "                assert member_text.count('\\n') == 0\n",
    "                yield create_sentiment_document(member.name, member_text, index)\n",
    "                index += 1\n",
    "\n",
    "alldocs = list(extract_documents())"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what a single document looks like.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T15:04:25.972010Z",
     "start_time": "2024-05-07T15:04:25.960505Z"
    }
   },
   "source": "print(alldocs[24000])",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentDocument(words=['The', 'movie', 'is', 'about', 'a', 'girl', \"who's\", 'not', 'going', 'to', 'a', 'bonfire', 'only', 'because', \"she's\", 'baby-sitting', 'that', 'night.', 'Nothing', 'weird', 'about', 'that,', 'right?', 'Until', '...', 'The', 'phone', 'rings.', 'Until', '...', 'The', 'phone', 'rings', 'again.', 'And', 'again', '...', 'And', 'again.', 'Those', 'are', 'not', 'some', 'stupid', 'prank', 'calls.', 'This', 'is', 'for', 'real.', 'If', 'you', 'wanna', 'see', 'how', 'the', 'girl', 'reacts,', 'just', 'watch', 'the', 'movie.<br', '/><br', '/>Great', 'atmosphere', 'filled', 'with', 'scary', 'sounds.', 'Very', 'well', 'performed', 'by', 'young', 'Camilla', 'Belle', 'who', 'got', 'the', 'lead', 'role.', 'I', 'see', 'in', 'her', 'some', 'great', 'potential', 'to', 'become', 'a', 'good', 'actress.', 'This', 'is', 'more', 'than', 'only', 'a', 'decent', 'thriller,', 'I', 'have', 'no', 'idea', 'why', \"it's\", 'so', 'underrated.', 'Anyway,', 'on', 'my', 'opinion', 'this', 'movie', 'deserves', 'more', 'than', 'only', '4/10.', '24%', 'of', 'all', 'voters', 'rated', 'the', 'movie', 'with', '1.', 'Get', 'serious,', 'people.', 'You', \"couldn't\", 'get', 'a', 'better', 'thriller', 'for', 'a', 'title', 'like', 'this.'], tags=[24000], split='test', sentiment=1.0)\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract our documents and split into training/test sets.\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:10:52.299851Z",
     "start_time": "2024-05-07T14:10:52.264961Z"
    }
   },
   "source": [
    "train_docs = [doc for doc in alldocs if doc.split == 'train']\ntest_docs = [doc for doc in alldocs if doc.split == 'test']\nprint(f'{len(alldocs)} docs: {len(train_docs)} train-sentiment, {len(test_docs)} test-sentiment')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 docs: 25000 train-sentiment, 25000 test-sentiment\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set-up Doc2Vec Training & Evaluation Models\n-------------------------------------------\n\nWe approximate the experiment of Le & Mikolov `\"Distributed Representations\nof Sentences and Documents\"\n<http://cs.stanford.edu/~quocle/paragraph_vector.pdf>`_ with guidance from\nMikolov's `example go.sh\n<https://groups.google.com/d/msg/word2vec-toolkit/Q49FIrNOQRo/J6KG8mUj45sJ>`_::\n\n    ./word2vec -train ../alldata-id.txt -output vectors.txt -cbow 0 -size 100 -window 10 -negative 5 -hs 0 -sample 1e-4 -threads 40 -binary 0 -iter 20 -min-count 1 -sentence-vectors 1\n\nWe vary the following parameter choices:\n\n* 100-dimensional vectors, as the 400-d vectors of the paper take a lot of\n  memory and, in our tests of this task, don't seem to offer much benefit\n* Similarly, frequent word subsampling seems to decrease sentiment-prediction\n  accuracy, so it's left out\n* ``cbow=0`` means skip-gram which is equivalent to the paper's 'PV-DBOW'\n  mode, matched in gensim with ``dm=0``\n* Added to that DBOW model are two DM models, one which averages context\n  vectors (\\ ``dm_mean``\\ ) and one which concatenates them (\\ ``dm_concat``\\ ,\n  resulting in a much larger, slower, more data-hungry model)\n* A ``min_count=2`` saves quite a bit of model memory, discarding only words\n  that appear in a single doc (and are thus no more expressive than the\n  unique-to-each doc vectors themselves)\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:12:33.370332Z",
     "start_time": "2024-05-07T14:12:10.938995Z"
    }
   },
   "source": [
    "import multiprocessing\nfrom collections import OrderedDict\n\nimport gensim.models.doc2vec\nassert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n\nfrom gensim.models.doc2vec import Doc2Vec\n\ncommon_kwargs = dict(\n    vector_size=100, epochs=20, min_count=2,\n    sample=0, workers=multiprocessing.cpu_count(), negative=5, hs=0,\n)\n\nsimple_models = [\n    # PV-DBOW plain\n    Doc2Vec(dm=0, **common_kwargs),\n    # PV-DM w/ default averaging; a higher starting alpha may improve CBOW/PV-DM modes\n    Doc2Vec(dm=1, window=10, alpha=0.05, comment='alpha=0.05', **common_kwargs),\n    # PV-DM w/ concatenation - big, slow, experimental mode\n    # window=5 (both sides) approximates paper's apparent 10-word total window size\n    Doc2Vec(dm=1, dm_concat=1, window=5, **common_kwargs),\n]\n\nfor model in simple_models:\n    model.build_vocab(alldocs)\n    print(f\"{model} vocabulary scanned & state initialized\")\n\nmodels_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:12:10,938 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc2,t8>', 'datetime': '2024-05-07T16:12:10.938995', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'created'}\n",
      "2024-05-07 16:12:10,938 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w10,mc2,t8>', 'datetime': '2024-05-07T16:12:10.938995', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'created'}\n",
      "2024-05-07 16:12:10,938 : INFO : using concatenative 1100-dimensional layer1\n",
      "2024-05-07 16:12:10,938 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/c,d100,n5,w5,mc2,t8>', 'datetime': '2024-05-07T16:12:10.938995', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'created'}\n",
      "2024-05-07 16:12:10,948 : INFO : collecting all words and their counts\n",
      "2024-05-07 16:12:10,948 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2024-05-07 16:12:11,308 : INFO : PROGRESS: at example #10000, processed 2292381 words (6320418 words/s), 150816 word types, 0 tags\n",
      "2024-05-07 16:12:11,744 : INFO : PROGRESS: at example #20000, processed 4573645 words (5287834 words/s), 238497 word types, 0 tags\n",
      "2024-05-07 16:12:12,212 : INFO : PROGRESS: at example #30000, processed 6865575 words (4824135 words/s), 312348 word types, 0 tags\n",
      "2024-05-07 16:12:12,704 : INFO : PROGRESS: at example #40000, processed 9190019 words (4819366 words/s), 377231 word types, 0 tags\n",
      "2024-05-07 16:12:13,171 : INFO : PROGRESS: at example #50000, processed 11557847 words (5034743 words/s), 438729 word types, 0 tags\n",
      "2024-05-07 16:12:13,618 : INFO : PROGRESS: at example #60000, processed 13899883 words (5339529 words/s), 493913 word types, 0 tags\n",
      "2024-05-07 16:12:14,022 : INFO : PROGRESS: at example #70000, processed 16270094 words (5855411 words/s), 548474 word types, 0 tags\n",
      "2024-05-07 16:12:14,408 : INFO : PROGRESS: at example #80000, processed 18598876 words (6023143 words/s), 598272 word types, 0 tags\n",
      "2024-05-07 16:12:14,801 : INFO : PROGRESS: at example #90000, processed 20916044 words (5904965 words/s), 646082 word types, 0 tags\n",
      "2024-05-07 16:12:15,216 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2024-05-07 16:12:15,216 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 16:12:15,890 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 265408 unique words (38.25% of original 693922, drops 428514)', 'datetime': '2024-05-07T16:12:15.890616', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 16:12:15,890 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 22851015 word corpus (98.16% of original 23279529, drops 428514)', 'datetime': '2024-05-07T16:12:15.890616', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 16:12:16,830 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2024-05-07 16:12:16,840 : INFO : sample=0 downsamples 0 most-common words\n",
      "2024-05-07 16:12:16,840 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 22851015 word corpus (100.0%% of prior 22851015)', 'datetime': '2024-05-07T16:12:16.840193', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 16:12:18,484 : INFO : estimated required memory for 265408 words and 100 dimensions: 405030400 bytes\n",
      "2024-05-07 16:12:18,484 : INFO : resetting layer weights\n",
      "2024-05-07 16:12:18,606 : INFO : collecting all words and their counts\n",
      "2024-05-07 16:12:18,606 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow,d100,n5,mc2,t8> vocabulary scanned & state initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:12:19,016 : INFO : PROGRESS: at example #10000, processed 2292381 words (5675641 words/s), 150816 word types, 0 tags\n",
      "2024-05-07 16:12:19,376 : INFO : PROGRESS: at example #20000, processed 4573645 words (6262479 words/s), 238497 word types, 0 tags\n",
      "2024-05-07 16:12:19,741 : INFO : PROGRESS: at example #30000, processed 6865575 words (6386203 words/s), 312348 word types, 0 tags\n",
      "2024-05-07 16:12:20,132 : INFO : PROGRESS: at example #40000, processed 9190019 words (5897541 words/s), 377231 word types, 0 tags\n",
      "2024-05-07 16:12:20,509 : INFO : PROGRESS: at example #50000, processed 11557847 words (6275154 words/s), 438729 word types, 0 tags\n",
      "2024-05-07 16:12:20,909 : INFO : PROGRESS: at example #60000, processed 13899883 words (5832528 words/s), 493913 word types, 0 tags\n",
      "2024-05-07 16:12:21,326 : INFO : PROGRESS: at example #70000, processed 16270094 words (5738096 words/s), 548474 word types, 0 tags\n",
      "2024-05-07 16:12:21,747 : INFO : PROGRESS: at example #80000, processed 18598876 words (5470709 words/s), 598272 word types, 0 tags\n",
      "2024-05-07 16:12:22,234 : INFO : PROGRESS: at example #90000, processed 20916044 words (4803261 words/s), 646082 word types, 0 tags\n",
      "2024-05-07 16:12:22,720 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2024-05-07 16:12:22,720 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 16:12:23,451 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 265408 unique words (38.25% of original 693922, drops 428514)', 'datetime': '2024-05-07T16:12:23.451974', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 16:12:23,451 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 22851015 word corpus (98.16% of original 23279529, drops 428514)', 'datetime': '2024-05-07T16:12:23.451974', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 16:12:24,374 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2024-05-07 16:12:24,384 : INFO : sample=0 downsamples 0 most-common words\n",
      "2024-05-07 16:12:24,384 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 22851015 word corpus (100.0%% of prior 22851015)', 'datetime': '2024-05-07T16:12:24.384473', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 16:12:26,017 : INFO : estimated required memory for 265408 words and 100 dimensions: 405030400 bytes\n",
      "2024-05-07 16:12:26,017 : INFO : resetting layer weights\n",
      "2024-05-07 16:12:26,147 : INFO : collecting all words and their counts\n",
      "2024-05-07 16:12:26,147 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dm/m,d100,n5,w10,mc2,t8> vocabulary scanned & state initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:12:26,491 : INFO : PROGRESS: at example #10000, processed 2292381 words (6682562 words/s), 150816 word types, 0 tags\n",
      "2024-05-07 16:12:26,841 : INFO : PROGRESS: at example #20000, processed 4573645 words (6522656 words/s), 238497 word types, 0 tags\n",
      "2024-05-07 16:12:27,221 : INFO : PROGRESS: at example #30000, processed 6865575 words (5967291 words/s), 312348 word types, 0 tags\n",
      "2024-05-07 16:12:27,641 : INFO : PROGRESS: at example #40000, processed 9190019 words (5551461 words/s), 377231 word types, 0 tags\n",
      "2024-05-07 16:12:28,052 : INFO : PROGRESS: at example #50000, processed 11557847 words (5868233 words/s), 438729 word types, 0 tags\n",
      "2024-05-07 16:12:28,437 : INFO : PROGRESS: at example #60000, processed 13899883 words (6050687 words/s), 493913 word types, 0 tags\n",
      "2024-05-07 16:12:28,813 : INFO : PROGRESS: at example #70000, processed 16270094 words (6233201 words/s), 548474 word types, 0 tags\n",
      "2024-05-07 16:12:29,185 : INFO : PROGRESS: at example #80000, processed 18598876 words (6284351 words/s), 598272 word types, 0 tags\n",
      "2024-05-07 16:12:29,565 : INFO : PROGRESS: at example #90000, processed 20916044 words (6229554 words/s), 646082 word types, 0 tags\n",
      "2024-05-07 16:12:29,974 : INFO : collected 693922 word types and 100000 unique tags from a corpus of 100000 examples and 23279529 words\n",
      "2024-05-07 16:12:29,974 : INFO : Creating a fresh vocabulary\n",
      "2024-05-07 16:12:30,665 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 265408 unique words (38.25% of original 693922, drops 428514)', 'datetime': '2024-05-07T16:12:30.665718', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 16:12:30,665 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 22851015 word corpus (98.16% of original 23279529, drops 428514)', 'datetime': '2024-05-07T16:12:30.665718', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 16:12:31,611 : INFO : deleting the raw counts dictionary of 693922 items\n",
      "2024-05-07 16:12:31,631 : INFO : sample=0 downsamples 0 most-common words\n",
      "2024-05-07 16:12:31,631 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 22851015 word corpus (100.0%% of prior 22851015)', 'datetime': '2024-05-07T16:12:31.631481', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'prepare_vocab'}\n",
      "2024-05-07 16:12:33,241 : INFO : estimated required memory for 265408 words and 100 dimensions: 1466662400 bytes\n",
      "2024-05-07 16:12:33,241 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dm/c,d100,n5,w5,mc2,t8> vocabulary scanned & state initialized\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le and Mikolov note that combining a paragraph vector from Distributed Bag of\nWords (DBOW) and Distributed Memory (DM) improves performance. We will\nfollow, pairing the models together for evaluation. Here, we concatenate the\nparagraph vectors obtained from each model with the help of a thin wrapper\nclass included in a gensim test module. (Note that this a separate, later\nconcatenation of output-vectors than the kind of input-window-concatenation\nenabled by the ``dm_concat=1`` mode above.)\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:15:21.258256Z",
     "start_time": "2024-05-07T14:15:21.128081Z"
    }
   },
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\nmodels_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[1]])\nmodels_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[2]])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:15:21,149 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-05-07 16:15:21,149 : INFO : built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\n",
      "2024-05-07 16:15:21,150 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...> from 9 documents (total 29 corpus positions)\", 'datetime': '2024-05-07T16:15:21.150095', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive Evaluation Methods\n-----------------------------\n\nGiven a document, our ``Doc2Vec`` models output a vector representation of the document.\nHow useful is a particular model?\nIn case of sentiment analysis, we want the ouput vector to reflect the sentiment in the input document.\nSo, in vector space, positive documents should be distant from negative documents.\n\nWe train a logistic regression from the training set:\n\n  - regressors (inputs): document vectors from the Doc2Vec model\n  - target (outpus): sentiment labels\n\nSo, this logistic regression will be able to predict sentiment given a document vector.\n\nNext, we test our logistic regression on the test set, and measure the rate of errors (incorrect predictions).\nIf the document vectors from the Doc2Vec model reflect the actual sentiment well, the error rate will be low.\n\nTherefore, the error rate of the logistic regression is indication of *how well* the given Doc2Vec model represents documents as vectors.\nWe can then compare different ``Doc2Vec`` models by looking at their error rates.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:16:40.059214Z",
     "start_time": "2024-05-07T14:15:47.095687Z"
    }
   },
   "source": [
    "import numpy as np\nimport statsmodels.api as sm\nfrom random import sample\n\ndef logistic_predictor_from_data(train_targets, train_regressors):\n    \"\"\"Fit a statsmodel logistic predictor on supplied data\"\"\"\n    logit = sm.Logit(train_targets, train_regressors)\n    predictor = logit.fit(disp=0)\n    # print(predictor.summary())\n    return predictor\n\ndef error_rate_for_model(test_model, train_set, test_set):\n    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n\n    train_targets = [doc.sentiment for doc in train_set]\n    train_regressors = [test_model.dv[doc.tags[0]] for doc in train_set]\n    train_regressors = sm.add_constant(train_regressors)\n    predictor = logistic_predictor_from_data(train_targets, train_regressors)\n\n    test_regressors = [test_model.dv[doc.tags[0]] for doc in test_set]\n    test_regressors = sm.add_constant(test_regressors)\n\n    # Predict & evaluate\n    test_predictions = predictor.predict(test_regressors)\n    corrects = sum(np.rint(test_predictions) == [doc.sentiment for doc in test_set])\n    errors = len(test_predictions) - corrects\n    error_rate = float(errors) / len(test_predictions)\n    return (error_rate, errors, len(test_predictions), predictor)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bulk Training & Per-Model Evaluation\n------------------------------------\n\nNote that doc-vector training is occurring on *all* documents of the dataset,\nwhich includes all TRAIN/TEST/DEV docs.  Because the native document-order\nhas similar-sentiment documents in large clumps – which is suboptimal for\ntraining – we work with once-shuffled copy of the training set.\n\nWe evaluate each model's sentiment predictive power based on error rate, and\nthe evaluation is done for each model.\n\n(On a 4-core 2.6Ghz Intel Core i7, these 20 passes training and evaluating 3\nmain models takes about an hour.)\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:16:40.062851Z",
     "start_time": "2024-05-07T14:16:40.060213Z"
    }
   },
   "source": [
    "from collections import defaultdict\nerror_rates = defaultdict(lambda: 1.0)  # To selectively print only best errors achieved"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:33:20.999902Z",
     "start_time": "2024-05-07T14:16:43.425710Z"
    }
   },
   "source": [
    "from random import shuffle\nshuffled_alldocs = alldocs[:]\nshuffle(shuffled_alldocs)\n\nfor model in simple_models:\n    print(f\"Training {model}\")\n    model.train(shuffled_alldocs, total_examples=len(shuffled_alldocs), epochs=model.epochs)\n\n    print(f\"\\nEvaluating {model}\")\n    err_rate, err_count, test_count, predictor = error_rate_for_model(model, train_docs, test_docs)\n    error_rates[str(model)] = err_rate\n    print(\"\\n%f %s\\n\" % (err_rate, model))\n\nfor model in [models_by_name['dbow+dmm'], models_by_name['dbow+dmc']]:\n    print(f\"\\nEvaluating {model}\")\n    err_rate, err_count, test_count, predictor = error_rate_for_model(model, train_docs, test_docs)\n    error_rates[str(model)] = err_rate\n    print(f\"\\n{err_rate} {model}\\n\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:16:43,474 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 8 workers on 265408 vocabulary and 100 features, using sg=1 hs=0 sample=0 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T16:16:43.474581', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Doc2Vec<dbow,d100,n5,mc2,t8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:16:44,487 : INFO : EPOCH 0 - PROGRESS: at 7.30% examples, 1682246 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:16:45,495 : INFO : EPOCH 0 - PROGRESS: at 15.97% examples, 1815587 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:16:46,497 : INFO : EPOCH 0 - PROGRESS: at 25.64% examples, 1951194 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:16:47,498 : INFO : EPOCH 0 - PROGRESS: at 36.98% examples, 2108581 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:16:48,499 : INFO : EPOCH 0 - PROGRESS: at 47.71% examples, 2178615 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:16:49,499 : INFO : EPOCH 0 - PROGRESS: at 58.02% examples, 2209534 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:16:50,494 : INFO : EPOCH 0 - PROGRESS: at 68.36% examples, 2231003 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:16:51,497 : INFO : EPOCH 0 - PROGRESS: at 77.53% examples, 2213648 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:16:52,500 : INFO : EPOCH 0 - PROGRESS: at 87.78% examples, 2233104 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:16:53,498 : INFO : EPOCH 0 - PROGRESS: at 98.45% examples, 2254383 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:16:53,643 : INFO : EPOCH 0: training on 23279529 raw words (22951015 effective words) took 10.2s, 2256713 effective words/s\n",
      "2024-05-07 16:16:54,649 : INFO : EPOCH 1 - PROGRESS: at 10.48% examples, 2406098 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:16:55,661 : INFO : EPOCH 1 - PROGRESS: at 21.13% examples, 2410280 words/s, in_qsize 15, out_qsize 1\n",
      "2024-05-07 16:16:56,677 : INFO : EPOCH 1 - PROGRESS: at 31.93% examples, 2418087 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:16:57,682 : INFO : EPOCH 1 - PROGRESS: at 42.35% examples, 2413038 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:16:58,678 : INFO : EPOCH 1 - PROGRESS: at 52.82% examples, 2405893 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:16:59,682 : INFO : EPOCH 1 - PROGRESS: at 63.55% examples, 2414168 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:00,693 : INFO : EPOCH 1 - PROGRESS: at 74.07% examples, 2409678 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:01,695 : INFO : EPOCH 1 - PROGRESS: at 84.61% examples, 2410747 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:17:02,700 : INFO : EPOCH 1 - PROGRESS: at 94.63% examples, 2399289 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:03,293 : INFO : EPOCH 1: training on 23279529 raw words (22951015 effective words) took 9.6s, 2380850 effective words/s\n",
      "2024-05-07 16:17:04,299 : INFO : EPOCH 2 - PROGRESS: at 9.99% examples, 2291795 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:05,301 : INFO : EPOCH 2 - PROGRESS: at 18.68% examples, 2134984 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:06,296 : INFO : EPOCH 2 - PROGRESS: at 28.93% examples, 2208777 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:07,302 : INFO : EPOCH 2 - PROGRESS: at 39.16% examples, 2242614 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:08,297 : INFO : EPOCH 2 - PROGRESS: at 51.37% examples, 2349475 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:17:09,302 : INFO : EPOCH 2 - PROGRESS: at 63.82% examples, 2434143 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:10,307 : INFO : EPOCH 2 - PROGRESS: at 76.26% examples, 2491971 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:11,303 : INFO : EPOCH 2 - PROGRESS: at 86.97% examples, 2490730 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:12,308 : INFO : EPOCH 2 - PROGRESS: at 99.30% examples, 2528573 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:12,358 : INFO : EPOCH 2: training on 23279529 raw words (22951015 effective words) took 9.1s, 2530835 effective words/s\n",
      "2024-05-07 16:17:13,373 : INFO : EPOCH 3 - PROGRESS: at 11.86% examples, 2709471 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:14,378 : INFO : EPOCH 3 - PROGRESS: at 23.35% examples, 2661822 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:17:15,373 : INFO : EPOCH 3 - PROGRESS: at 35.63% examples, 2712449 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:16,388 : INFO : EPOCH 3 - PROGRESS: at 47.13% examples, 2689766 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:17:17,382 : INFO : EPOCH 3 - PROGRESS: at 59.29% examples, 2707183 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:18,395 : INFO : EPOCH 3 - PROGRESS: at 70.70% examples, 2687250 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:19,401 : INFO : EPOCH 3 - PROGRESS: at 82.35% examples, 2682717 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:20,406 : INFO : EPOCH 3 - PROGRESS: at 93.56% examples, 2669032 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:21,032 : INFO : EPOCH 3: training on 23279529 raw words (22951015 effective words) took 8.7s, 2649266 effective words/s\n",
      "2024-05-07 16:17:22,037 : INFO : EPOCH 4 - PROGRESS: at 11.50% examples, 2639860 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:23,040 : INFO : EPOCH 4 - PROGRESS: at 22.33% examples, 2545310 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:17:24,036 : INFO : EPOCH 4 - PROGRESS: at 32.30% examples, 2457660 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:25,040 : INFO : EPOCH 4 - PROGRESS: at 43.67% examples, 2498137 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:17:26,044 : INFO : EPOCH 4 - PROGRESS: at 55.60% examples, 2543038 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:27,048 : INFO : EPOCH 4 - PROGRESS: at 67.45% examples, 2571116 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:17:28,050 : INFO : EPOCH 4 - PROGRESS: at 78.44% examples, 2560097 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:17:29,056 : INFO : EPOCH 4 - PROGRESS: at 89.05% examples, 2546937 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:29,972 : INFO : EPOCH 4: training on 23279529 raw words (22951015 effective words) took 8.9s, 2567881 effective words/s\n",
      "2024-05-07 16:17:30,977 : INFO : EPOCH 5 - PROGRESS: at 12.16% examples, 2790713 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:31,971 : INFO : EPOCH 5 - PROGRESS: at 24.38% examples, 2784581 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:32,976 : INFO : EPOCH 5 - PROGRESS: at 36.59% examples, 2789224 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:33,980 : INFO : EPOCH 5 - PROGRESS: at 47.72% examples, 2727738 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:34,983 : INFO : EPOCH 5 - PROGRESS: at 58.75% examples, 2685039 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:35,995 : INFO : EPOCH 5 - PROGRESS: at 70.44% examples, 2681308 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:17:36,995 : INFO : EPOCH 5 - PROGRESS: at 80.72% examples, 2636382 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:37,995 : INFO : EPOCH 5 - PROGRESS: at 92.21% examples, 2638013 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:38,645 : INFO : EPOCH 5: training on 23279529 raw words (22951015 effective words) took 8.7s, 2645105 effective words/s\n",
      "2024-05-07 16:17:39,658 : INFO : EPOCH 6 - PROGRESS: at 10.82% examples, 2475637 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:40,663 : INFO : EPOCH 6 - PROGRESS: at 22.80% examples, 2600272 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:41,666 : INFO : EPOCH 6 - PROGRESS: at 35.22% examples, 2677782 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:42,669 : INFO : EPOCH 6 - PROGRESS: at 47.67% examples, 2722352 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:43,674 : INFO : EPOCH 6 - PROGRESS: at 60.03% examples, 2743390 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:17:44,674 : INFO : EPOCH 6 - PROGRESS: at 71.40% examples, 2716838 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:45,677 : INFO : EPOCH 6 - PROGRESS: at 81.64% examples, 2663049 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:46,688 : INFO : EPOCH 6 - PROGRESS: at 91.92% examples, 2627381 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:47,383 : INFO : EPOCH 6: training on 23279529 raw words (22951015 effective words) took 8.7s, 2629328 effective words/s\n",
      "2024-05-07 16:17:48,388 : INFO : EPOCH 7 - PROGRESS: at 12.16% examples, 2791343 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:49,394 : INFO : EPOCH 7 - PROGRESS: at 24.56% examples, 2806217 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:50,395 : INFO : EPOCH 7 - PROGRESS: at 36.18% examples, 2752974 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:17:51,400 : INFO : EPOCH 7 - PROGRESS: at 48.15% examples, 2747641 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:52,407 : INFO : EPOCH 7 - PROGRESS: at 59.99% examples, 2741465 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:53,403 : INFO : EPOCH 7 - PROGRESS: at 71.89% examples, 2738476 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:54,409 : INFO : EPOCH 7 - PROGRESS: at 83.69% examples, 2733249 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:55,403 : INFO : EPOCH 7 - PROGRESS: at 95.40% examples, 2729419 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:55,805 : INFO : EPOCH 7: training on 23279529 raw words (22951015 effective words) took 8.4s, 2726447 effective words/s\n",
      "2024-05-07 16:17:56,811 : INFO : EPOCH 8 - PROGRESS: at 12.12% examples, 2775036 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:17:57,824 : INFO : EPOCH 8 - PROGRESS: at 23.86% examples, 2705482 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:58,829 : INFO : EPOCH 8 - PROGRESS: at 35.35% examples, 2681775 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:17:59,834 : INFO : EPOCH 8 - PROGRESS: at 46.74% examples, 2662212 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:00,838 : INFO : EPOCH 8 - PROGRESS: at 59.06% examples, 2690339 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:01,842 : INFO : EPOCH 8 - PROGRESS: at 70.52% examples, 2678881 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:02,857 : INFO : EPOCH 8 - PROGRESS: at 82.35% examples, 2678012 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:03,864 : INFO : EPOCH 8 - PROGRESS: at 91.92% examples, 2620532 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:04,579 : INFO : EPOCH 8: training on 23279529 raw words (22951015 effective words) took 8.8s, 2616993 effective words/s\n",
      "2024-05-07 16:18:05,583 : INFO : EPOCH 9 - PROGRESS: at 10.57% examples, 2427766 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:06,587 : INFO : EPOCH 9 - PROGRESS: at 21.70% examples, 2479095 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:07,594 : INFO : EPOCH 9 - PROGRESS: at 33.04% examples, 2513030 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:18:08,592 : INFO : EPOCH 9 - PROGRESS: at 44.14% examples, 2525571 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:09,596 : INFO : EPOCH 9 - PROGRESS: at 55.30% examples, 2530235 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:10,597 : INFO : EPOCH 9 - PROGRESS: at 65.26% examples, 2485227 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:11,603 : INFO : EPOCH 9 - PROGRESS: at 76.56% examples, 2497565 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:12,607 : INFO : EPOCH 9 - PROGRESS: at 87.44% examples, 2500889 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:18:13,611 : INFO : EPOCH 9 - PROGRESS: at 98.67% examples, 2509039 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:13,731 : INFO : EPOCH 9: training on 23279529 raw words (22951015 effective words) took 9.1s, 2509223 effective words/s\n",
      "2024-05-07 16:18:14,729 : INFO : EPOCH 10 - PROGRESS: at 10.95% examples, 2515125 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:18:15,734 : INFO : EPOCH 10 - PROGRESS: at 22.16% examples, 2532222 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:16,737 : INFO : EPOCH 10 - PROGRESS: at 33.37% examples, 2540383 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:18:17,742 : INFO : EPOCH 10 - PROGRESS: at 44.37% examples, 2539616 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:18,738 : INFO : EPOCH 10 - PROGRESS: at 55.57% examples, 2542908 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:19,739 : INFO : EPOCH 10 - PROGRESS: at 65.82% examples, 2509101 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:20,744 : INFO : EPOCH 10 - PROGRESS: at 76.95% examples, 2512805 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:21,739 : INFO : EPOCH 10 - PROGRESS: at 87.95% examples, 2519031 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:22,743 : INFO : EPOCH 10 - PROGRESS: at 99.39% examples, 2530099 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:22,793 : INFO : EPOCH 10: training on 23279529 raw words (22951015 effective words) took 9.1s, 2532561 effective words/s\n",
      "2024-05-07 16:18:23,803 : INFO : EPOCH 11 - PROGRESS: at 11.46% examples, 2637454 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:24,808 : INFO : EPOCH 11 - PROGRESS: at 23.53% examples, 2683426 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:18:25,801 : INFO : EPOCH 11 - PROGRESS: at 35.14% examples, 2676113 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:26,814 : INFO : EPOCH 11 - PROGRESS: at 47.13% examples, 2692427 words/s, in_qsize 16, out_qsize 1\n",
      "2024-05-07 16:18:27,816 : INFO : EPOCH 11 - PROGRESS: at 59.06% examples, 2695779 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:28,822 : INFO : EPOCH 11 - PROGRESS: at 70.86% examples, 2696938 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:29,817 : INFO : EPOCH 11 - PROGRESS: at 82.35% examples, 2689130 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:30,820 : INFO : EPOCH 11 - PROGRESS: at 93.79% examples, 2683759 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:31,324 : INFO : EPOCH 11: training on 23279529 raw words (22951015 effective words) took 8.5s, 2693063 effective words/s\n",
      "2024-05-07 16:18:32,328 : INFO : EPOCH 12 - PROGRESS: at 12.24% examples, 2814166 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:33,333 : INFO : EPOCH 12 - PROGRESS: at 24.13% examples, 2747344 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:18:34,328 : INFO : EPOCH 12 - PROGRESS: at 35.98% examples, 2737637 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:35,334 : INFO : EPOCH 12 - PROGRESS: at 47.45% examples, 2712441 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:18:36,330 : INFO : EPOCH 12 - PROGRESS: at 59.59% examples, 2725647 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:18:37,333 : INFO : EPOCH 12 - PROGRESS: at 71.57% examples, 2727859 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:38,338 : INFO : EPOCH 12 - PROGRESS: at 83.03% examples, 2712483 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:39,343 : INFO : EPOCH 12 - PROGRESS: at 95.05% examples, 2720490 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:39,748 : INFO : EPOCH 12: training on 23279529 raw words (22951015 effective words) took 8.4s, 2723251 effective words/s\n",
      "2024-05-07 16:18:40,763 : INFO : EPOCH 13 - PROGRESS: at 11.64% examples, 2671289 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:41,758 : INFO : EPOCH 13 - PROGRESS: at 23.27% examples, 2657976 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:42,763 : INFO : EPOCH 13 - PROGRESS: at 34.90% examples, 2657456 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:18:43,758 : INFO : EPOCH 13 - PROGRESS: at 46.87% examples, 2683080 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:44,762 : INFO : EPOCH 13 - PROGRESS: at 58.92% examples, 2696819 words/s, in_qsize 16, out_qsize 1\n",
      "2024-05-07 16:18:45,768 : INFO : EPOCH 13 - PROGRESS: at 70.75% examples, 2696913 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:46,763 : INFO : EPOCH 13 - PROGRESS: at 82.35% examples, 2692483 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:47,767 : INFO : EPOCH 13 - PROGRESS: at 94.14% examples, 2696905 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:48,258 : INFO : EPOCH 13: training on 23279529 raw words (22951015 effective words) took 8.5s, 2697464 effective words/s\n",
      "2024-05-07 16:18:49,275 : INFO : EPOCH 14 - PROGRESS: at 11.81% examples, 2689884 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:50,279 : INFO : EPOCH 14 - PROGRESS: at 23.86% examples, 2709048 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:51,289 : INFO : EPOCH 14 - PROGRESS: at 35.55% examples, 2695652 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:52,289 : INFO : EPOCH 14 - PROGRESS: at 47.72% examples, 2717641 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:53,293 : INFO : EPOCH 14 - PROGRESS: at 59.37% examples, 2708414 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:54,298 : INFO : EPOCH 14 - PROGRESS: at 71.33% examples, 2711526 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:55,293 : INFO : EPOCH 14 - PROGRESS: at 83.03% examples, 2708120 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:56,298 : INFO : EPOCH 14 - PROGRESS: at 94.42% examples, 2697725 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:56,780 : INFO : EPOCH 14: training on 23279529 raw words (22951015 effective words) took 8.5s, 2695678 effective words/s\n",
      "2024-05-07 16:18:57,792 : INFO : EPOCH 15 - PROGRESS: at 11.14% examples, 2552426 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:58,791 : INFO : EPOCH 15 - PROGRESS: at 22.56% examples, 2576589 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:18:59,794 : INFO : EPOCH 15 - PROGRESS: at 34.48% examples, 2622787 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:00,795 : INFO : EPOCH 15 - PROGRESS: at 46.29% examples, 2647744 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:19:01,808 : INFO : EPOCH 15 - PROGRESS: at 58.06% examples, 2652105 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:02,811 : INFO : EPOCH 15 - PROGRESS: at 69.69% examples, 2648870 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:03,814 : INFO : EPOCH 15 - PROGRESS: at 81.40% examples, 2653826 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:04,816 : INFO : EPOCH 15 - PROGRESS: at 93.70% examples, 2678307 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:05,330 : INFO : EPOCH 15: training on 23279529 raw words (22951015 effective words) took 8.5s, 2686829 effective words/s\n",
      "2024-05-07 16:19:06,328 : INFO : EPOCH 16 - PROGRESS: at 11.76% examples, 2704622 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:07,334 : INFO : EPOCH 16 - PROGRESS: at 23.65% examples, 2697476 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:08,342 : INFO : EPOCH 16 - PROGRESS: at 35.38% examples, 2692246 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:09,346 : INFO : EPOCH 16 - PROGRESS: at 47.13% examples, 2688984 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:10,351 : INFO : EPOCH 16 - PROGRESS: at 59.37% examples, 2709300 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:11,356 : INFO : EPOCH 16 - PROGRESS: at 71.33% examples, 2711231 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:12,360 : INFO : EPOCH 16 - PROGRESS: at 83.15% examples, 2712191 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:13,355 : INFO : EPOCH 16 - PROGRESS: at 94.88% examples, 2711618 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:19:13,809 : INFO : EPOCH 16: training on 23279529 raw words (22951015 effective words) took 8.5s, 2707979 effective words/s\n",
      "2024-05-07 16:19:14,814 : INFO : EPOCH 17 - PROGRESS: at 11.89% examples, 2725219 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:15,818 : INFO : EPOCH 17 - PROGRESS: at 23.86% examples, 2723236 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:16,822 : INFO : EPOCH 17 - PROGRESS: at 35.43% examples, 2695603 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:17,817 : INFO : EPOCH 17 - PROGRESS: at 47.05% examples, 2689119 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:18,820 : INFO : EPOCH 17 - PROGRESS: at 59.50% examples, 2719646 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:19,825 : INFO : EPOCH 17 - PROGRESS: at 71.65% examples, 2729424 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:20,820 : INFO : EPOCH 17 - PROGRESS: at 83.41% examples, 2725282 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:21,825 : INFO : EPOCH 17 - PROGRESS: at 95.10% examples, 2720629 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:22,248 : INFO : EPOCH 17: training on 23279529 raw words (22951015 effective words) took 8.4s, 2719445 effective words/s\n",
      "2024-05-07 16:19:23,252 : INFO : EPOCH 18 - PROGRESS: at 11.98% examples, 2757629 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:24,257 : INFO : EPOCH 18 - PROGRESS: at 23.81% examples, 2724322 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:25,250 : INFO : EPOCH 18 - PROGRESS: at 35.63% examples, 2719193 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:26,254 : INFO : EPOCH 18 - PROGRESS: at 47.13% examples, 2697460 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:27,260 : INFO : EPOCH 18 - PROGRESS: at 58.71% examples, 2684694 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:28,263 : INFO : EPOCH 18 - PROGRESS: at 70.16% examples, 2671989 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:19:29,278 : INFO : EPOCH 18 - PROGRESS: at 81.68% examples, 2666554 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:30,275 : INFO : EPOCH 18 - PROGRESS: at 93.52% examples, 2674770 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:30,839 : INFO : EPOCH 18: training on 23279529 raw words (22951015 effective words) took 8.6s, 2673096 effective words/s\n",
      "2024-05-07 16:19:31,842 : INFO : EPOCH 19 - PROGRESS: at 11.86% examples, 2717252 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:32,847 : INFO : EPOCH 19 - PROGRESS: at 24.33% examples, 2776854 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:19:33,851 : INFO : EPOCH 19 - PROGRESS: at 36.47% examples, 2780692 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:19:34,845 : INFO : EPOCH 19 - PROGRESS: at 48.02% examples, 2745669 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:35,850 : INFO : EPOCH 19 - PROGRESS: at 59.50% examples, 2722004 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:36,855 : INFO : EPOCH 19 - PROGRESS: at 71.03% examples, 2705482 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:37,860 : INFO : EPOCH 19 - PROGRESS: at 82.66% examples, 2698797 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:38,864 : INFO : EPOCH 19 - PROGRESS: at 93.97% examples, 2689437 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:39,378 : INFO : EPOCH 19: training on 23279529 raw words (22951015 effective words) took 8.5s, 2690058 effective words/s\n",
      "2024-05-07 16:19:39,378 : INFO : Doc2Vec lifecycle event {'msg': 'training on 465590580 raw words (459020300 effective words) took 175.9s, 2609485 effective words/s', 'datetime': '2024-05-07T16:19:39.378338', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Doc2Vec<dbow,d100,n5,mc2,t8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:19:39,851 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 8 workers on 265408 vocabulary and 100 features, using sg=0 hs=0 sample=0 negative=5 window=10 shrink_windows=True', 'datetime': '2024-05-07T16:19:39.851558', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.104080 Doc2Vec<dbow,d100,n5,mc2,t8>\n",
      "\n",
      "Training Doc2Vec<dm/m,d100,n5,w10,mc2,t8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:19:40,852 : INFO : EPOCH 0 - PROGRESS: at 6.95% examples, 1613528 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:41,867 : INFO : EPOCH 0 - PROGRESS: at 14.34% examples, 1635540 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:42,872 : INFO : EPOCH 0 - PROGRESS: at 21.75% examples, 1648525 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:43,877 : INFO : EPOCH 0 - PROGRESS: at 28.93% examples, 1651316 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:44,882 : INFO : EPOCH 0 - PROGRESS: at 35.77% examples, 1630994 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:45,882 : INFO : EPOCH 0 - PROGRESS: at 42.56% examples, 1621826 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:46,892 : INFO : EPOCH 0 - PROGRESS: at 49.78% examples, 1622067 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:19:47,901 : INFO : EPOCH 0 - PROGRESS: at 56.71% examples, 1616588 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:19:48,897 : INFO : EPOCH 0 - PROGRESS: at 63.52% examples, 1609994 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:49,903 : INFO : EPOCH 0 - PROGRESS: at 70.74% examples, 1613012 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:19:50,908 : INFO : EPOCH 0 - PROGRESS: at 77.48% examples, 1605322 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:51,913 : INFO : EPOCH 0 - PROGRESS: at 84.07% examples, 1598490 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:52,917 : INFO : EPOCH 0 - PROGRESS: at 90.91% examples, 1597183 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:53,923 : INFO : EPOCH 0 - PROGRESS: at 97.47% examples, 1590903 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:54,332 : INFO : EPOCH 0: training on 23279529 raw words (22951015 effective words) took 14.5s, 1585157 effective words/s\n",
      "2024-05-07 16:19:55,349 : INFO : EPOCH 1 - PROGRESS: at 6.70% examples, 1541171 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:56,354 : INFO : EPOCH 1 - PROGRESS: at 13.63% examples, 1557168 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:57,359 : INFO : EPOCH 1 - PROGRESS: at 20.79% examples, 1579570 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:58,354 : INFO : EPOCH 1 - PROGRESS: at 27.65% examples, 1580263 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:19:59,359 : INFO : EPOCH 1 - PROGRESS: at 34.86% examples, 1589095 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:00,364 : INFO : EPOCH 1 - PROGRESS: at 41.69% examples, 1588286 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:20:01,378 : INFO : EPOCH 1 - PROGRESS: at 48.49% examples, 1579180 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:02,383 : INFO : EPOCH 1 - PROGRESS: at 55.27% examples, 1574981 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:03,389 : INFO : EPOCH 1 - PROGRESS: at 61.56% examples, 1559820 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:20:04,397 : INFO : EPOCH 1 - PROGRESS: at 68.36% examples, 1558140 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:05,402 : INFO : EPOCH 1 - PROGRESS: at 75.43% examples, 1561622 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:06,410 : INFO : EPOCH 1 - PROGRESS: at 81.81% examples, 1554058 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:20:07,406 : INFO : EPOCH 1 - PROGRESS: at 88.72% examples, 1558356 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:08,411 : INFO : EPOCH 1 - PROGRESS: at 95.60% examples, 1558991 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:20:09,047 : INFO : EPOCH 1: training on 23279529 raw words (22951015 effective words) took 14.7s, 1560686 effective words/s\n",
      "2024-05-07 16:20:10,051 : INFO : EPOCH 2 - PROGRESS: at 6.87% examples, 1586172 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:11,068 : INFO : EPOCH 2 - PROGRESS: at 13.89% examples, 1579705 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:12,081 : INFO : EPOCH 2 - PROGRESS: at 20.79% examples, 1573106 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:13,081 : INFO : EPOCH 2 - PROGRESS: at 27.78% examples, 1583889 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:14,080 : INFO : EPOCH 2 - PROGRESS: at 34.74% examples, 1579204 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:15,084 : INFO : EPOCH 2 - PROGRESS: at 41.73% examples, 1586327 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:16,099 : INFO : EPOCH 2 - PROGRESS: at 48.81% examples, 1587513 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:17,105 : INFO : EPOCH 2 - PROGRESS: at 55.74% examples, 1585327 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:18,110 : INFO : EPOCH 2 - PROGRESS: at 62.94% examples, 1591321 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:19,115 : INFO : EPOCH 2 - PROGRESS: at 70.07% examples, 1594017 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:20,131 : INFO : EPOCH 2 - PROGRESS: at 77.12% examples, 1594206 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:21,136 : INFO : EPOCH 2 - PROGRESS: at 84.07% examples, 1594850 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:22,130 : INFO : EPOCH 2 - PROGRESS: at 91.04% examples, 1596607 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:23,145 : INFO : EPOCH 2 - PROGRESS: at 97.95% examples, 1595187 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:20:23,429 : INFO : EPOCH 2: training on 23279529 raw words (22951015 effective words) took 14.4s, 1595774 effective words/s\n",
      "2024-05-07 16:20:24,434 : INFO : EPOCH 3 - PROGRESS: at 7.12% examples, 1653225 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:25,452 : INFO : EPOCH 3 - PROGRESS: at 14.12% examples, 1609079 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:26,457 : INFO : EPOCH 3 - PROGRESS: at 21.22% examples, 1610688 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:27,453 : INFO : EPOCH 3 - PROGRESS: at 27.96% examples, 1597349 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:28,457 : INFO : EPOCH 3 - PROGRESS: at 35.38% examples, 1612696 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:29,462 : INFO : EPOCH 3 - PROGRESS: at 42.30% examples, 1611666 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:30,467 : INFO : EPOCH 3 - PROGRESS: at 49.45% examples, 1610655 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:31,473 : INFO : EPOCH 3 - PROGRESS: at 56.50% examples, 1611641 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:32,488 : INFO : EPOCH 3 - PROGRESS: at 63.60% examples, 1611212 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:33,483 : INFO : EPOCH 3 - PROGRESS: at 70.78% examples, 1613229 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:34,487 : INFO : EPOCH 3 - PROGRESS: at 77.81% examples, 1612255 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:35,492 : INFO : EPOCH 3 - PROGRESS: at 84.81% examples, 1613149 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:36,497 : INFO : EPOCH 3 - PROGRESS: at 91.79% examples, 1614030 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:37,501 : INFO : EPOCH 3 - PROGRESS: at 98.87% examples, 1613108 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:20:37,651 : INFO : EPOCH 3: training on 23279529 raw words (22951015 effective words) took 14.2s, 1614734 effective words/s\n",
      "2024-05-07 16:20:38,656 : INFO : EPOCH 4 - PROGRESS: at 6.91% examples, 1603654 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:39,660 : INFO : EPOCH 4 - PROGRESS: at 13.98% examples, 1603374 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:40,655 : INFO : EPOCH 4 - PROGRESS: at 21.18% examples, 1614077 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:41,660 : INFO : EPOCH 4 - PROGRESS: at 28.22% examples, 1616218 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:42,665 : INFO : EPOCH 4 - PROGRESS: at 35.31% examples, 1614081 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:43,670 : INFO : EPOCH 4 - PROGRESS: at 42.25% examples, 1613065 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:44,665 : INFO : EPOCH 4 - PROGRESS: at 49.24% examples, 1608280 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:45,682 : INFO : EPOCH 4 - PROGRESS: at 56.12% examples, 1602926 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:46,677 : INFO : EPOCH 4 - PROGRESS: at 63.52% examples, 1613102 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:47,677 : INFO : EPOCH 4 - PROGRESS: at 70.52% examples, 1610987 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:48,682 : INFO : EPOCH 4 - PROGRESS: at 77.53% examples, 1609719 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:49,687 : INFO : EPOCH 4 - PROGRESS: at 84.65% examples, 1612711 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:50,692 : INFO : EPOCH 4 - PROGRESS: at 91.58% examples, 1612293 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:51,698 : INFO : EPOCH 4 - PROGRESS: at 98.62% examples, 1611689 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:20:51,888 : INFO : EPOCH 4: training on 23279529 raw words (22951015 effective words) took 14.2s, 1612402 effective words/s\n",
      "2024-05-07 16:20:52,903 : INFO : EPOCH 5 - PROGRESS: at 7.08% examples, 1628225 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:53,900 : INFO : EPOCH 5 - PROGRESS: at 14.21% examples, 1621935 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:54,906 : INFO : EPOCH 5 - PROGRESS: at 21.45% examples, 1628294 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:55,911 : INFO : EPOCH 5 - PROGRESS: at 28.39% examples, 1621817 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:20:56,907 : INFO : EPOCH 5 - PROGRESS: at 35.51% examples, 1620630 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:57,911 : INFO : EPOCH 5 - PROGRESS: at 42.48% examples, 1619484 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:20:58,916 : INFO : EPOCH 5 - PROGRESS: at 49.75% examples, 1623185 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:20:59,921 : INFO : EPOCH 5 - PROGRESS: at 56.45% examples, 1611721 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:21:00,926 : INFO : EPOCH 5 - PROGRESS: at 63.77% examples, 1618176 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:01,931 : INFO : EPOCH 5 - PROGRESS: at 70.95% examples, 1619193 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:02,937 : INFO : EPOCH 5 - PROGRESS: at 77.73% examples, 1612052 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:03,931 : INFO : EPOCH 5 - PROGRESS: at 84.97% examples, 1617824 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:04,934 : INFO : EPOCH 5 - PROGRESS: at 91.92% examples, 1617515 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:05,945 : INFO : EPOCH 5 - PROGRESS: at 99.08% examples, 1618278 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:06,055 : INFO : EPOCH 5: training on 23279529 raw words (22951015 effective words) took 14.2s, 1620096 effective words/s\n",
      "2024-05-07 16:21:07,061 : INFO : EPOCH 6 - PROGRESS: at 6.91% examples, 1600733 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:08,066 : INFO : EPOCH 6 - PROGRESS: at 13.75% examples, 1579361 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:09,071 : INFO : EPOCH 6 - PROGRESS: at 20.70% examples, 1577451 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:10,071 : INFO : EPOCH 6 - PROGRESS: at 27.21% examples, 1557745 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:11,071 : INFO : EPOCH 6 - PROGRESS: at 34.08% examples, 1557159 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:12,081 : INFO : EPOCH 6 - PROGRESS: at 40.69% examples, 1551439 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:13,085 : INFO : EPOCH 6 - PROGRESS: at 47.84% examples, 1560519 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:14,090 : INFO : EPOCH 6 - PROGRESS: at 54.60% examples, 1558007 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:15,093 : INFO : EPOCH 6 - PROGRESS: at 61.05% examples, 1549429 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:21:16,116 : INFO : EPOCH 6 - PROGRESS: at 67.96% examples, 1549483 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:17,112 : INFO : EPOCH 6 - PROGRESS: at 74.84% examples, 1550880 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:18,125 : INFO : EPOCH 6 - PROGRESS: at 81.68% examples, 1551273 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:19,128 : INFO : EPOCH 6 - PROGRESS: at 88.15% examples, 1548091 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:20,142 : INFO : EPOCH 6 - PROGRESS: at 94.67% examples, 1543163 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:20,946 : INFO : EPOCH 6: training on 23279529 raw words (22951015 effective words) took 14.9s, 1541643 effective words/s\n",
      "2024-05-07 16:21:21,953 : INFO : EPOCH 7 - PROGRESS: at 6.04% examples, 1395820 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:22,972 : INFO : EPOCH 7 - PROGRESS: at 12.55% examples, 1431782 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:21:23,970 : INFO : EPOCH 7 - PROGRESS: at 19.55% examples, 1486244 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:24,971 : INFO : EPOCH 7 - PROGRESS: at 26.19% examples, 1495071 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:25,988 : INFO : EPOCH 7 - PROGRESS: at 33.12% examples, 1506932 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:26,982 : INFO : EPOCH 7 - PROGRESS: at 40.17% examples, 1528539 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:27,992 : INFO : EPOCH 7 - PROGRESS: at 46.50% examples, 1514985 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:28,996 : INFO : EPOCH 7 - PROGRESS: at 52.98% examples, 1510543 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:29,990 : INFO : EPOCH 7 - PROGRESS: at 59.75% examples, 1514772 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:30,995 : INFO : EPOCH 7 - PROGRESS: at 66.58% examples, 1520401 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:31,991 : INFO : EPOCH 7 - PROGRESS: at 73.67% examples, 1528992 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:33,005 : INFO : EPOCH 7 - PROGRESS: at 80.77% examples, 1536623 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:34,009 : INFO : EPOCH 7 - PROGRESS: at 87.77% examples, 1542434 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:35,045 : INFO : EPOCH 7 - PROGRESS: at 95.01% examples, 1547487 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:35,729 : INFO : EPOCH 7: training on 23279529 raw words (22951015 effective words) took 14.8s, 1553153 effective words/s\n",
      "2024-05-07 16:21:36,735 : INFO : EPOCH 8 - PROGRESS: at 6.70% examples, 1551655 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:21:37,749 : INFO : EPOCH 8 - PROGRESS: at 13.89% examples, 1586017 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:38,758 : INFO : EPOCH 8 - PROGRESS: at 21.05% examples, 1596612 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:39,753 : INFO : EPOCH 8 - PROGRESS: at 28.18% examples, 1608456 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:40,769 : INFO : EPOCH 8 - PROGRESS: at 35.38% examples, 1609589 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:41,768 : INFO : EPOCH 8 - PROGRESS: at 42.47% examples, 1614854 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:42,773 : INFO : EPOCH 8 - PROGRESS: at 49.75% examples, 1618304 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:43,778 : INFO : EPOCH 8 - PROGRESS: at 56.80% examples, 1617891 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:21:44,784 : INFO : EPOCH 8 - PROGRESS: at 63.77% examples, 1615252 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:45,799 : INFO : EPOCH 8 - PROGRESS: at 70.83% examples, 1612537 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:46,804 : INFO : EPOCH 8 - PROGRESS: at 77.65% examples, 1606673 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:47,809 : INFO : EPOCH 8 - PROGRESS: at 84.89% examples, 1612684 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:48,804 : INFO : EPOCH 8 - PROGRESS: at 91.79% examples, 1612178 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:49,809 : INFO : EPOCH 8 - PROGRESS: at 99.00% examples, 1614285 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:49,939 : INFO : EPOCH 8: training on 23279529 raw words (22951015 effective words) took 14.2s, 1615557 effective words/s\n",
      "2024-05-07 16:21:50,953 : INFO : EPOCH 9 - PROGRESS: at 6.91% examples, 1592465 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:51,957 : INFO : EPOCH 9 - PROGRESS: at 13.80% examples, 1579184 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:52,961 : INFO : EPOCH 9 - PROGRESS: at 20.70% examples, 1573922 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:53,966 : INFO : EPOCH 9 - PROGRESS: at 27.92% examples, 1594830 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:21:54,966 : INFO : EPOCH 9 - PROGRESS: at 35.03% examples, 1597261 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:55,966 : INFO : EPOCH 9 - PROGRESS: at 42.02% examples, 1601093 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:56,970 : INFO : EPOCH 9 - PROGRESS: at 49.16% examples, 1602517 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:57,974 : INFO : EPOCH 9 - PROGRESS: at 56.28% examples, 1606262 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:21:58,980 : INFO : EPOCH 9 - PROGRESS: at 63.52% examples, 1610586 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:00,005 : INFO : EPOCH 9 - PROGRESS: at 70.70% examples, 1610202 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:01,010 : INFO : EPOCH 9 - PROGRESS: at 77.74% examples, 1609402 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:02,015 : INFO : EPOCH 9 - PROGRESS: at 84.97% examples, 1613978 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:03,019 : INFO : EPOCH 9 - PROGRESS: at 91.98% examples, 1614837 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:04,024 : INFO : EPOCH 9 - PROGRESS: at 99.22% examples, 1616786 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:04,124 : INFO : EPOCH 9: training on 23279529 raw words (22951015 effective words) took 14.2s, 1617893 effective words/s\n",
      "2024-05-07 16:22:05,129 : INFO : EPOCH 10 - PROGRESS: at 7.04% examples, 1633703 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:06,143 : INFO : EPOCH 10 - PROGRESS: at 14.25% examples, 1625500 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:07,148 : INFO : EPOCH 10 - PROGRESS: at 21.22% examples, 1611423 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:08,152 : INFO : EPOCH 10 - PROGRESS: at 28.09% examples, 1604971 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:09,157 : INFO : EPOCH 10 - PROGRESS: at 35.03% examples, 1595321 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:10,163 : INFO : EPOCH 10 - PROGRESS: at 41.81% examples, 1591349 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:11,169 : INFO : EPOCH 10 - PROGRESS: at 49.31% examples, 1607070 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:12,164 : INFO : EPOCH 10 - PROGRESS: at 56.45% examples, 1610267 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:13,179 : INFO : EPOCH 10 - PROGRESS: at 63.55% examples, 1610540 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:14,194 : INFO : EPOCH 10 - PROGRESS: at 70.70% examples, 1609091 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:15,199 : INFO : EPOCH 10 - PROGRESS: at 77.66% examples, 1606852 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:16,204 : INFO : EPOCH 10 - PROGRESS: at 84.81% examples, 1610670 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:17,219 : INFO : EPOCH 10 - PROGRESS: at 91.92% examples, 1612415 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:18,225 : INFO : EPOCH 10 - PROGRESS: at 99.04% examples, 1613561 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:18,335 : INFO : EPOCH 10: training on 23279529 raw words (22951015 effective words) took 14.2s, 1615458 effective words/s\n",
      "2024-05-07 16:22:19,350 : INFO : EPOCH 11 - PROGRESS: at 6.78% examples, 1559925 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:20,355 : INFO : EPOCH 11 - PROGRESS: at 13.68% examples, 1563036 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:21,361 : INFO : EPOCH 11 - PROGRESS: at 20.70% examples, 1572607 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:22:22,375 : INFO : EPOCH 11 - PROGRESS: at 27.87% examples, 1587214 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:23,380 : INFO : EPOCH 11 - PROGRESS: at 34.98% examples, 1590534 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:24,390 : INFO : EPOCH 11 - PROGRESS: at 42.07% examples, 1597589 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:25,388 : INFO : EPOCH 11 - PROGRESS: at 49.16% examples, 1598259 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:26,393 : INFO : EPOCH 11 - PROGRESS: at 56.24% examples, 1601201 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:27,418 : INFO : EPOCH 11 - PROGRESS: at 63.23% examples, 1595992 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:28,432 : INFO : EPOCH 11 - PROGRESS: at 70.15% examples, 1593411 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:29,447 : INFO : EPOCH 11 - PROGRESS: at 77.49% examples, 1598413 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:30,453 : INFO : EPOCH 11 - PROGRESS: at 84.68% examples, 1603841 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:31,451 : INFO : EPOCH 11 - PROGRESS: at 91.62% examples, 1604316 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:32,466 : INFO : EPOCH 11 - PROGRESS: at 98.79% examples, 1605669 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:32,626 : INFO : EPOCH 11: training on 23279529 raw words (22951015 effective words) took 14.3s, 1607368 effective words/s\n",
      "2024-05-07 16:22:33,629 : INFO : EPOCH 12 - PROGRESS: at 6.87% examples, 1596955 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:34,624 : INFO : EPOCH 12 - PROGRESS: at 13.89% examples, 1594922 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:35,629 : INFO : EPOCH 12 - PROGRESS: at 21.27% examples, 1621062 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:36,634 : INFO : EPOCH 12 - PROGRESS: at 28.35% examples, 1624115 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:37,639 : INFO : EPOCH 12 - PROGRESS: at 35.55% examples, 1624610 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:22:38,643 : INFO : EPOCH 12 - PROGRESS: at 42.60% examples, 1626188 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:39,647 : INFO : EPOCH 12 - PROGRESS: at 49.78% examples, 1625491 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:40,652 : INFO : EPOCH 12 - PROGRESS: at 56.80% examples, 1622112 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:41,660 : INFO : EPOCH 12 - PROGRESS: at 63.86% examples, 1620470 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:42,663 : INFO : EPOCH 12 - PROGRESS: at 71.24% examples, 1626409 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:43,668 : INFO : EPOCH 12 - PROGRESS: at 78.09% examples, 1620704 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:22:44,673 : INFO : EPOCH 12 - PROGRESS: at 84.97% examples, 1617242 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:45,678 : INFO : EPOCH 12 - PROGRESS: at 91.79% examples, 1614664 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:46,683 : INFO : EPOCH 12 - PROGRESS: at 99.00% examples, 1616431 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:46,803 : INFO : EPOCH 12: training on 23279529 raw words (22951015 effective words) took 14.2s, 1618339 effective words/s\n",
      "2024-05-07 16:22:47,808 : INFO : EPOCH 13 - PROGRESS: at 7.34% examples, 1702483 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:22:48,813 : INFO : EPOCH 13 - PROGRESS: at 14.38% examples, 1646997 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:49,827 : INFO : EPOCH 13 - PROGRESS: at 21.51% examples, 1631187 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:50,833 : INFO : EPOCH 13 - PROGRESS: at 28.53% examples, 1626432 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:51,838 : INFO : EPOCH 13 - PROGRESS: at 35.55% examples, 1618478 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:52,855 : INFO : EPOCH 13 - PROGRESS: at 42.47% examples, 1614225 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:53,859 : INFO : EPOCH 13 - PROGRESS: at 49.90% examples, 1622971 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:54,873 : INFO : EPOCH 13 - PROGRESS: at 56.99% examples, 1621451 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:55,878 : INFO : EPOCH 13 - PROGRESS: at 64.19% examples, 1622559 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:56,893 : INFO : EPOCH 13 - PROGRESS: at 71.36% examples, 1622313 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:22:57,898 : INFO : EPOCH 13 - PROGRESS: at 78.44% examples, 1622235 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:58,892 : INFO : EPOCH 13 - PROGRESS: at 85.44% examples, 1621590 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:22:59,907 : INFO : EPOCH 13 - PROGRESS: at 92.60% examples, 1623503 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:23:00,923 : INFO : EPOCH 13 - PROGRESS: at 99.70% examples, 1622396 words/s, in_qsize 7, out_qsize 1\n",
      "2024-05-07 16:23:00,933 : INFO : EPOCH 13: training on 23279529 raw words (22951015 effective words) took 14.1s, 1624851 effective words/s\n",
      "2024-05-07 16:23:01,948 : INFO : EPOCH 14 - PROGRESS: at 6.91% examples, 1595897 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:02,963 : INFO : EPOCH 14 - PROGRESS: at 14.11% examples, 1605578 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:23:03,957 : INFO : EPOCH 14 - PROGRESS: at 21.18% examples, 1605766 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:04,962 : INFO : EPOCH 14 - PROGRESS: at 28.61% examples, 1630876 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:05,970 : INFO : EPOCH 14 - PROGRESS: at 35.73% examples, 1625535 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:06,974 : INFO : EPOCH 14 - PROGRESS: at 42.82% examples, 1627491 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:07,989 : INFO : EPOCH 14 - PROGRESS: at 49.86% examples, 1621661 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:09,014 : INFO : EPOCH 14 - PROGRESS: at 57.03% examples, 1620077 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:10,019 : INFO : EPOCH 14 - PROGRESS: at 64.23% examples, 1622091 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:11,024 : INFO : EPOCH 14 - PROGRESS: at 71.40% examples, 1623250 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:12,021 : INFO : EPOCH 14 - PROGRESS: at 78.48% examples, 1622779 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:13,026 : INFO : EPOCH 14 - PROGRESS: at 85.47% examples, 1621853 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:14,031 : INFO : EPOCH 14 - PROGRESS: at 92.42% examples, 1620992 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:15,035 : INFO : EPOCH 14 - PROGRESS: at 99.70% examples, 1623780 words/s, in_qsize 7, out_qsize 1\n",
      "2024-05-07 16:23:15,055 : INFO : EPOCH 14: training on 23279529 raw words (22951015 effective words) took 14.1s, 1625849 effective words/s\n",
      "2024-05-07 16:23:16,060 : INFO : EPOCH 15 - PROGRESS: at 6.87% examples, 1596812 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:17,063 : INFO : EPOCH 15 - PROGRESS: at 14.02% examples, 1609931 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:23:18,069 : INFO : EPOCH 15 - PROGRESS: at 21.18% examples, 1613806 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:19,074 : INFO : EPOCH 15 - PROGRESS: at 28.30% examples, 1619191 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:20,069 : INFO : EPOCH 15 - PROGRESS: at 35.38% examples, 1616980 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:21,072 : INFO : EPOCH 15 - PROGRESS: at 42.43% examples, 1619734 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:22,071 : INFO : EPOCH 15 - PROGRESS: at 49.40% examples, 1613538 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:23,086 : INFO : EPOCH 15 - PROGRESS: at 56.37% examples, 1609907 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:24,091 : INFO : EPOCH 15 - PROGRESS: at 63.52% examples, 1611532 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:25,107 : INFO : EPOCH 15 - PROGRESS: at 70.65% examples, 1611384 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:26,108 : INFO : EPOCH 15 - PROGRESS: at 77.53% examples, 1607166 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:27,112 : INFO : EPOCH 15 - PROGRESS: at 84.46% examples, 1605878 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:28,126 : INFO : EPOCH 15 - PROGRESS: at 91.71% examples, 1611246 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:29,131 : INFO : EPOCH 15 - PROGRESS: at 98.67% examples, 1609506 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:29,301 : INFO : EPOCH 15: training on 23279529 raw words (22951015 effective words) took 14.2s, 1611762 effective words/s\n",
      "2024-05-07 16:23:30,306 : INFO : EPOCH 16 - PROGRESS: at 7.04% examples, 1626281 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:23:31,310 : INFO : EPOCH 16 - PROGRESS: at 14.12% examples, 1614842 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:32,315 : INFO : EPOCH 16 - PROGRESS: at 21.45% examples, 1631685 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:33,313 : INFO : EPOCH 16 - PROGRESS: at 28.57% examples, 1634035 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:23:34,318 : INFO : EPOCH 16 - PROGRESS: at 35.55% examples, 1624836 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:35,313 : INFO : EPOCH 16 - PROGRESS: at 42.60% examples, 1626436 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:36,326 : INFO : EPOCH 16 - PROGRESS: at 49.78% examples, 1624784 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:37,321 : INFO : EPOCH 16 - PROGRESS: at 56.80% examples, 1622575 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:38,329 : INFO : EPOCH 16 - PROGRESS: at 63.94% examples, 1623186 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:39,333 : INFO : EPOCH 16 - PROGRESS: at 71.11% examples, 1624444 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:40,350 : INFO : EPOCH 16 - PROGRESS: at 78.28% examples, 1624769 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:41,358 : INFO : EPOCH 16 - PROGRESS: at 85.36% examples, 1624063 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:42,362 : INFO : EPOCH 16 - PROGRESS: at 92.51% examples, 1626912 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:23:43,356 : INFO : EPOCH 16 - PROGRESS: at 99.50% examples, 1624832 words/s, in_qsize 12, out_qsize 0\n",
      "2024-05-07 16:23:43,416 : INFO : EPOCH 16: training on 23279529 raw words (22951015 effective words) took 14.1s, 1626529 effective words/s\n",
      "2024-05-07 16:23:44,420 : INFO : EPOCH 17 - PROGRESS: at 6.78% examples, 1577642 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:45,415 : INFO : EPOCH 17 - PROGRESS: at 13.80% examples, 1585291 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:46,429 : INFO : EPOCH 17 - PROGRESS: at 20.79% examples, 1580748 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:47,433 : INFO : EPOCH 17 - PROGRESS: at 27.87% examples, 1592585 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:48,438 : INFO : EPOCH 17 - PROGRESS: at 35.03% examples, 1596166 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:49,451 : INFO : EPOCH 17 - PROGRESS: at 42.14% examples, 1604434 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:50,448 : INFO : EPOCH 17 - PROGRESS: at 49.23% examples, 1604153 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:51,448 : INFO : EPOCH 17 - PROGRESS: at 55.52% examples, 1584095 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:52,462 : INFO : EPOCH 17 - PROGRESS: at 62.59% examples, 1586443 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:53,468 : INFO : EPOCH 17 - PROGRESS: at 69.52% examples, 1584314 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:54,473 : INFO : EPOCH 17 - PROGRESS: at 76.60% examples, 1586260 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:23:55,477 : INFO : EPOCH 17 - PROGRESS: at 83.86% examples, 1594001 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:56,482 : INFO : EPOCH 17 - PROGRESS: at 90.91% examples, 1596758 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:57,504 : INFO : EPOCH 17 - PROGRESS: at 98.06% examples, 1598373 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:57,754 : INFO : EPOCH 17: training on 23279529 raw words (22951015 effective words) took 14.3s, 1600839 effective words/s\n",
      "2024-05-07 16:23:58,757 : INFO : EPOCH 18 - PROGRESS: at 7.00% examples, 1618897 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:23:59,773 : INFO : EPOCH 18 - PROGRESS: at 14.12% examples, 1611090 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:00,771 : INFO : EPOCH 18 - PROGRESS: at 21.13% examples, 1604739 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:01,785 : INFO : EPOCH 18 - PROGRESS: at 28.30% examples, 1613606 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:02,780 : INFO : EPOCH 18 - PROGRESS: at 35.38% examples, 1612181 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:03,786 : INFO : EPOCH 18 - PROGRESS: at 42.39% examples, 1614804 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:04,790 : INFO : EPOCH 18 - PROGRESS: at 49.71% examples, 1619831 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:24:05,795 : INFO : EPOCH 18 - PROGRESS: at 56.70% examples, 1618220 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:24:06,789 : INFO : EPOCH 18 - PROGRESS: at 63.77% examples, 1617679 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:07,794 : INFO : EPOCH 18 - PROGRESS: at 70.91% examples, 1618708 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:08,798 : INFO : EPOCH 18 - PROGRESS: at 77.81% examples, 1614918 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:24:09,793 : INFO : EPOCH 18 - PROGRESS: at 84.73% examples, 1614058 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:10,798 : INFO : EPOCH 18 - PROGRESS: at 91.92% examples, 1618563 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:11,804 : INFO : EPOCH 18 - PROGRESS: at 98.91% examples, 1616840 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:11,944 : INFO : EPOCH 18: training on 23279529 raw words (22951015 effective words) took 14.2s, 1617617 effective words/s\n",
      "2024-05-07 16:24:12,960 : INFO : EPOCH 19 - PROGRESS: at 6.74% examples, 1557780 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:13,955 : INFO : EPOCH 19 - PROGRESS: at 13.46% examples, 1542260 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:14,970 : INFO : EPOCH 19 - PROGRESS: at 20.79% examples, 1576395 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:15,984 : INFO : EPOCH 19 - PROGRESS: at 27.87% examples, 1586899 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:16,979 : INFO : EPOCH 19 - PROGRESS: at 34.94% examples, 1588930 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:17,984 : INFO : EPOCH 19 - PROGRESS: at 41.82% examples, 1589238 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:24:18,989 : INFO : EPOCH 19 - PROGRESS: at 48.72% examples, 1586334 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:19,988 : INFO : EPOCH 19 - PROGRESS: at 55.48% examples, 1581770 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:20,997 : INFO : EPOCH 19 - PROGRESS: at 62.43% examples, 1580728 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:21,996 : INFO : EPOCH 19 - PROGRESS: at 69.30% examples, 1579558 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:23,008 : INFO : EPOCH 19 - PROGRESS: at 75.76% examples, 1569403 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:24,003 : INFO : EPOCH 19 - PROGRESS: at 82.48% examples, 1567958 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:25,008 : INFO : EPOCH 19 - PROGRESS: at 89.40% examples, 1571586 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:26,011 : INFO : EPOCH 19 - PROGRESS: at 96.41% examples, 1574108 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:26,517 : INFO : EPOCH 19: training on 23279529 raw words (22951015 effective words) took 14.6s, 1575927 effective words/s\n",
      "2024-05-07 16:24:26,517 : INFO : Doc2Vec lifecycle event {'msg': 'training on 465590580 raw words (459020300 effective words) took 286.7s, 1601255 effective words/s', 'datetime': '2024-05-07T16:24:26.517065', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Doc2Vec<dm/m,d100,n5,w10,mc2,t8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:24:26,890 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 8 workers on 265409 vocabulary and 1100 features, using sg=0 hs=0 sample=0 negative=5 window=5 shrink_windows=True', 'datetime': '2024-05-07T16:24:26.890395', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.169760 Doc2Vec<dm/m,d100,n5,w10,mc2,t8>\n",
      "\n",
      "Training Doc2Vec<dm/c,d100,n5,w5,mc2,t8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:24:27,908 : INFO : EPOCH 0 - PROGRESS: at 2.25% examples, 518185 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:24:28,908 : INFO : EPOCH 0 - PROGRESS: at 5.08% examples, 587939 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:29,912 : INFO : EPOCH 0 - PROGRESS: at 7.96% examples, 610336 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:30,909 : INFO : EPOCH 0 - PROGRESS: at 10.95% examples, 626375 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:31,956 : INFO : EPOCH 0 - PROGRESS: at 13.98% examples, 635672 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:24:32,975 : INFO : EPOCH 0 - PROGRESS: at 17.07% examples, 643118 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:33,983 : INFO : EPOCH 0 - PROGRESS: at 20.02% examples, 647957 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:24:34,983 : INFO : EPOCH 0 - PROGRESS: at 22.94% examples, 650461 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:24:35,992 : INFO : EPOCH 0 - PROGRESS: at 25.94% examples, 654862 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:24:37,031 : INFO : EPOCH 0 - PROGRESS: at 29.06% examples, 658509 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:38,031 : INFO : EPOCH 0 - PROGRESS: at 32.18% examples, 661715 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:39,044 : INFO : EPOCH 0 - PROGRESS: at 35.31% examples, 665632 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:24:40,057 : INFO : EPOCH 0 - PROGRESS: at 38.29% examples, 667582 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:41,074 : INFO : EPOCH 0 - PROGRESS: at 41.19% examples, 666742 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:42,080 : INFO : EPOCH 0 - PROGRESS: at 44.19% examples, 668043 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:24:43,079 : INFO : EPOCH 0 - PROGRESS: at 47.32% examples, 670157 words/s, in_qsize 15, out_qsize 1\n",
      "2024-05-07 16:24:44,089 : INFO : EPOCH 0 - PROGRESS: at 50.38% examples, 671493 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:45,118 : INFO : EPOCH 0 - PROGRESS: at 53.30% examples, 670195 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:46,125 : INFO : EPOCH 0 - PROGRESS: at 56.41% examples, 672614 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:47,146 : INFO : EPOCH 0 - PROGRESS: at 59.63% examples, 674955 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:48,151 : INFO : EPOCH 0 - PROGRESS: at 62.73% examples, 676457 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:24:49,150 : INFO : EPOCH 0 - PROGRESS: at 65.78% examples, 677232 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:50,156 : INFO : EPOCH 0 - PROGRESS: at 68.92% examples, 678857 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:24:51,161 : INFO : EPOCH 0 - PROGRESS: at 71.81% examples, 678432 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:52,188 : INFO : EPOCH 0 - PROGRESS: at 74.98% examples, 679134 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:53,197 : INFO : EPOCH 0 - PROGRESS: at 78.02% examples, 679566 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:54,201 : INFO : EPOCH 0 - PROGRESS: at 81.11% examples, 680675 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:55,208 : INFO : EPOCH 0 - PROGRESS: at 84.25% examples, 682112 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:24:56,236 : INFO : EPOCH 0 - PROGRESS: at 87.33% examples, 682936 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:57,246 : INFO : EPOCH 0 - PROGRESS: at 90.57% examples, 684905 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:58,260 : INFO : EPOCH 0 - PROGRESS: at 93.67% examples, 685660 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:24:59,259 : INFO : EPOCH 0 - PROGRESS: at 96.75% examples, 686362 words/s, in_qsize 15, out_qsize 1\n",
      "2024-05-07 16:25:00,267 : INFO : EPOCH 0 - PROGRESS: at 99.90% examples, 687220 words/s, in_qsize 2, out_qsize 1\n",
      "2024-05-07 16:25:00,267 : INFO : EPOCH 0: training on 23279529 raw words (22951015 effective words) took 33.4s, 687702 effective words/s\n",
      "2024-05-07 16:25:01,334 : INFO : EPOCH 1 - PROGRESS: at 3.00% examples, 667256 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:02,384 : INFO : EPOCH 1 - PROGRESS: at 6.39% examples, 703370 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:03,391 : INFO : EPOCH 1 - PROGRESS: at 9.75% examples, 717940 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:04,400 : INFO : EPOCH 1 - PROGRESS: at 13.01% examples, 724464 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:05,419 : INFO : EPOCH 1 - PROGRESS: at 16.35% examples, 727851 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:06,426 : INFO : EPOCH 1 - PROGRESS: at 19.53% examples, 727405 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:07,434 : INFO : EPOCH 1 - PROGRESS: at 22.56% examples, 722707 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:08,448 : INFO : EPOCH 1 - PROGRESS: at 25.86% examples, 726408 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:09,452 : INFO : EPOCH 1 - PROGRESS: at 29.19% examples, 730167 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:10,461 : INFO : EPOCH 1 - PROGRESS: at 32.51% examples, 731103 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:11,468 : INFO : EPOCH 1 - PROGRESS: at 35.77% examples, 731688 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:12,483 : INFO : EPOCH 1 - PROGRESS: at 39.01% examples, 733165 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:13,481 : INFO : EPOCH 1 - PROGRESS: at 42.22% examples, 733898 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:14,480 : INFO : EPOCH 1 - PROGRESS: at 45.52% examples, 734768 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:15,502 : INFO : EPOCH 1 - PROGRESS: at 48.57% examples, 730862 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:16,521 : INFO : EPOCH 1 - PROGRESS: at 51.82% examples, 730624 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:17,568 : INFO : EPOCH 1 - PROGRESS: at 55.19% examples, 731558 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:18,568 : INFO : EPOCH 1 - PROGRESS: at 58.42% examples, 731638 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:19,585 : INFO : EPOCH 1 - PROGRESS: at 61.74% examples, 732750 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:20,592 : INFO : EPOCH 1 - PROGRESS: at 65.08% examples, 734124 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:21,609 : INFO : EPOCH 1 - PROGRESS: at 68.31% examples, 733716 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:22,609 : INFO : EPOCH 1 - PROGRESS: at 71.12% examples, 729440 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:23,618 : INFO : EPOCH 1 - PROGRESS: at 74.45% examples, 730735 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:24,630 : INFO : EPOCH 1 - PROGRESS: at 77.69% examples, 730679 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:25,647 : INFO : EPOCH 1 - PROGRESS: at 80.96% examples, 731581 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:26,647 : INFO : EPOCH 1 - PROGRESS: at 84.03% examples, 730579 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:27,650 : INFO : EPOCH 1 - PROGRESS: at 87.02% examples, 729359 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:28,660 : INFO : EPOCH 1 - PROGRESS: at 90.26% examples, 729800 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:29,686 : INFO : EPOCH 1 - PROGRESS: at 93.63% examples, 730811 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:30,683 : INFO : EPOCH 1 - PROGRESS: at 96.75% examples, 730316 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:31,614 : INFO : EPOCH 1: training on 23279529 raw words (22951015 effective words) took 31.3s, 732377 effective words/s\n",
      "2024-05-07 16:25:32,642 : INFO : EPOCH 2 - PROGRESS: at 2.99% examples, 688878 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:33,652 : INFO : EPOCH 2 - PROGRESS: at 6.39% examples, 728631 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:34,657 : INFO : EPOCH 2 - PROGRESS: at 9.83% examples, 742518 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:35,675 : INFO : EPOCH 2 - PROGRESS: at 13.05% examples, 740246 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:36,675 : INFO : EPOCH 2 - PROGRESS: at 16.44% examples, 744500 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:37,674 : INFO : EPOCH 2 - PROGRESS: at 19.73% examples, 746251 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:38,692 : INFO : EPOCH 2 - PROGRESS: at 22.89% examples, 742171 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:39,699 : INFO : EPOCH 2 - PROGRESS: at 26.19% examples, 744505 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:40,705 : INFO : EPOCH 2 - PROGRESS: at 29.65% examples, 747503 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:41,730 : INFO : EPOCH 2 - PROGRESS: at 33.17% examples, 750509 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:42,738 : INFO : EPOCH 2 - PROGRESS: at 36.42% examples, 750289 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:43,778 : INFO : EPOCH 2 - PROGRESS: at 39.76% examples, 750405 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:44,796 : INFO : EPOCH 2 - PROGRESS: at 43.13% examples, 750785 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:45,805 : INFO : EPOCH 2 - PROGRESS: at 46.42% examples, 750150 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:46,807 : INFO : EPOCH 2 - PROGRESS: at 49.75% examples, 750284 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:47,853 : INFO : EPOCH 2 - PROGRESS: at 53.16% examples, 750614 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:48,852 : INFO : EPOCH 2 - PROGRESS: at 56.67% examples, 753501 words/s, in_qsize 16, out_qsize 1\n",
      "2024-05-07 16:25:49,870 : INFO : EPOCH 2 - PROGRESS: at 60.11% examples, 755081 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:50,879 : INFO : EPOCH 2 - PROGRESS: at 63.55% examples, 756191 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:51,900 : INFO : EPOCH 2 - PROGRESS: at 66.97% examples, 756921 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:52,909 : INFO : EPOCH 2 - PROGRESS: at 70.48% examples, 758470 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:53,910 : INFO : EPOCH 2 - PROGRESS: at 73.98% examples, 760513 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:54,912 : INFO : EPOCH 2 - PROGRESS: at 77.44% examples, 761602 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:55,912 : INFO : EPOCH 2 - PROGRESS: at 80.77% examples, 762384 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:56,921 : INFO : EPOCH 2 - PROGRESS: at 84.25% examples, 763241 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:57,939 : INFO : EPOCH 2 - PROGRESS: at 87.61% examples, 763863 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:25:58,938 : INFO : EPOCH 2 - PROGRESS: at 91.00% examples, 764248 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:25:59,947 : INFO : EPOCH 2 - PROGRESS: at 94.42% examples, 764906 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:00,955 : INFO : EPOCH 2 - PROGRESS: at 97.82% examples, 765338 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:01,563 : INFO : EPOCH 2: training on 23279529 raw words (22951015 effective words) took 29.9s, 766389 effective words/s\n",
      "2024-05-07 16:26:02,571 : INFO : EPOCH 3 - PROGRESS: at 3.28% examples, 770612 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:03,580 : INFO : EPOCH 3 - PROGRESS: at 6.70% examples, 776173 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:04,589 : INFO : EPOCH 3 - PROGRESS: at 10.33% examples, 784584 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:05,597 : INFO : EPOCH 3 - PROGRESS: at 13.76% examples, 785690 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:06,605 : INFO : EPOCH 3 - PROGRESS: at 17.35% examples, 790107 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:07,611 : INFO : EPOCH 3 - PROGRESS: at 20.82% examples, 790336 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:08,610 : INFO : EPOCH 3 - PROGRESS: at 24.34% examples, 790826 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:09,618 : INFO : EPOCH 3 - PROGRESS: at 27.83% examples, 794166 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:10,626 : INFO : EPOCH 3 - PROGRESS: at 31.41% examples, 794362 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:11,635 : INFO : EPOCH 3 - PROGRESS: at 35.03% examples, 796397 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:12,632 : INFO : EPOCH 3 - PROGRESS: at 38.45% examples, 797041 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:13,640 : INFO : EPOCH 3 - PROGRESS: at 41.90% examples, 796648 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:14,638 : INFO : EPOCH 3 - PROGRESS: at 45.48% examples, 797931 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:15,645 : INFO : EPOCH 3 - PROGRESS: at 49.02% examples, 798321 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:16,659 : INFO : EPOCH 3 - PROGRESS: at 52.57% examples, 798193 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:17,665 : INFO : EPOCH 3 - PROGRESS: at 56.04% examples, 798044 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:18,678 : INFO : EPOCH 3 - PROGRESS: at 59.55% examples, 797450 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:19,685 : INFO : EPOCH 3 - PROGRESS: at 62.98% examples, 796436 words/s, in_qsize 16, out_qsize 2\n",
      "2024-05-07 16:26:20,694 : INFO : EPOCH 3 - PROGRESS: at 66.42% examples, 796376 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:21,711 : INFO : EPOCH 3 - PROGRESS: at 69.95% examples, 795231 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:22,733 : INFO : EPOCH 3 - PROGRESS: at 73.40% examples, 795026 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:23,748 : INFO : EPOCH 3 - PROGRESS: at 77.12% examples, 796162 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:24,753 : INFO : EPOCH 3 - PROGRESS: at 80.59% examples, 797231 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:25,779 : INFO : EPOCH 3 - PROGRESS: at 84.11% examples, 796543 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:26,782 : INFO : EPOCH 3 - PROGRESS: at 87.61% examples, 797446 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:27,798 : INFO : EPOCH 3 - PROGRESS: at 91.20% examples, 797994 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:28,805 : INFO : EPOCH 3 - PROGRESS: at 94.79% examples, 798718 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:29,807 : INFO : EPOCH 3 - PROGRESS: at 98.33% examples, 799115 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:30,264 : INFO : EPOCH 3: training on 23279529 raw words (22951015 effective words) took 28.7s, 799844 effective words/s\n",
      "2024-05-07 16:26:31,290 : INFO : EPOCH 4 - PROGRESS: at 3.32% examples, 761930 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:32,326 : INFO : EPOCH 4 - PROGRESS: at 7.04% examples, 795178 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:33,373 : INFO : EPOCH 4 - PROGRESS: at 10.82% examples, 800097 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:34,371 : INFO : EPOCH 4 - PROGRESS: at 14.52% examples, 810635 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:35,378 : INFO : EPOCH 4 - PROGRESS: at 18.11% examples, 811660 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:36,396 : INFO : EPOCH 4 - PROGRESS: at 21.80% examples, 813974 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:37,394 : INFO : EPOCH 4 - PROGRESS: at 25.20% examples, 810644 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:38,413 : INFO : EPOCH 4 - PROGRESS: at 28.77% examples, 810169 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:39,431 : INFO : EPOCH 4 - PROGRESS: at 32.34% examples, 808132 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:40,458 : INFO : EPOCH 4 - PROGRESS: at 35.63% examples, 801246 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:41,457 : INFO : EPOCH 4 - PROGRESS: at 39.13% examples, 802445 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:42,465 : INFO : EPOCH 4 - PROGRESS: at 42.52% examples, 800455 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:43,483 : INFO : EPOCH 4 - PROGRESS: at 46.13% examples, 800252 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:44,502 : INFO : EPOCH 4 - PROGRESS: at 49.81% examples, 802178 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:45,502 : INFO : EPOCH 4 - PROGRESS: at 53.25% examples, 801019 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:46,507 : INFO : EPOCH 4 - PROGRESS: at 56.87% examples, 803052 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:47,523 : INFO : EPOCH 4 - PROGRESS: at 60.46% examples, 803188 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:48,538 : INFO : EPOCH 4 - PROGRESS: at 64.19% examples, 805323 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:49,548 : INFO : EPOCH 4 - PROGRESS: at 67.76% examples, 805189 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:50,548 : INFO : EPOCH 4 - PROGRESS: at 71.40% examples, 806517 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:51,557 : INFO : EPOCH 4 - PROGRESS: at 75.08% examples, 807565 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:52,575 : INFO : EPOCH 4 - PROGRESS: at 78.48% examples, 806319 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:53,573 : INFO : EPOCH 4 - PROGRESS: at 82.11% examples, 807337 words/s, in_qsize 16, out_qsize 1\n",
      "2024-05-07 16:26:54,581 : INFO : EPOCH 4 - PROGRESS: at 85.64% examples, 807996 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:26:55,596 : INFO : EPOCH 4 - PROGRESS: at 89.22% examples, 808617 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:56,603 : INFO : EPOCH 4 - PROGRESS: at 92.89% examples, 809690 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:57,610 : INFO : EPOCH 4 - PROGRESS: at 96.54% examples, 810428 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:26:58,569 : INFO : EPOCH 4: training on 23279529 raw words (22951015 effective words) took 28.3s, 811013 effective words/s\n",
      "2024-05-07 16:26:59,596 : INFO : EPOCH 5 - PROGRESS: at 3.32% examples, 766214 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:27:00,603 : INFO : EPOCH 5 - PROGRESS: at 7.04% examples, 804828 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:01,619 : INFO : EPOCH 5 - PROGRESS: at 10.79% examples, 811237 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:27:02,627 : INFO : EPOCH 5 - PROGRESS: at 14.47% examples, 819022 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:03,649 : INFO : EPOCH 5 - PROGRESS: at 18.21% examples, 821839 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:04,657 : INFO : EPOCH 5 - PROGRESS: at 21.84% examples, 820518 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:27:05,674 : INFO : EPOCH 5 - PROGRESS: at 25.48% examples, 823471 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:06,672 : INFO : EPOCH 5 - PROGRESS: at 29.19% examples, 826727 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:07,693 : INFO : EPOCH 5 - PROGRESS: at 32.99% examples, 827476 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:27:08,699 : INFO : EPOCH 5 - PROGRESS: at 36.55% examples, 827121 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:27:09,706 : INFO : EPOCH 5 - PROGRESS: at 40.21% examples, 828624 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:10,724 : INFO : EPOCH 5 - PROGRESS: at 43.94% examples, 829654 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:27:11,731 : INFO : EPOCH 5 - PROGRESS: at 47.72% examples, 830901 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:12,738 : INFO : EPOCH 5 - PROGRESS: at 51.45% examples, 831885 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:13,745 : INFO : EPOCH 5 - PROGRESS: at 54.90% examples, 829328 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:14,753 : INFO : EPOCH 5 - PROGRESS: at 58.54% examples, 829170 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:15,771 : INFO : EPOCH 5 - PROGRESS: at 62.21% examples, 829072 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:16,768 : INFO : EPOCH 5 - PROGRESS: at 65.89% examples, 829657 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:17,787 : INFO : EPOCH 5 - PROGRESS: at 69.65% examples, 830123 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:27:18,793 : INFO : EPOCH 5 - PROGRESS: at 73.31% examples, 831175 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:27:19,787 : INFO : EPOCH 5 - PROGRESS: at 77.08% examples, 831687 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:20,805 : INFO : EPOCH 5 - PROGRESS: at 80.46% examples, 829983 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:21,833 : INFO : EPOCH 5 - PROGRESS: at 84.03% examples, 828185 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:22,859 : INFO : EPOCH 5 - PROGRESS: at 87.44% examples, 826161 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:23,859 : INFO : EPOCH 5 - PROGRESS: at 90.62% examples, 822137 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:24,889 : INFO : EPOCH 5 - PROGRESS: at 93.84% examples, 818401 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:25,913 : INFO : EPOCH 5 - PROGRESS: at 97.27% examples, 816511 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:26,620 : INFO : EPOCH 5: training on 23279529 raw words (22951015 effective words) took 28.1s, 818063 effective words/s\n",
      "2024-05-07 16:27:27,634 : INFO : EPOCH 6 - PROGRESS: at 3.37% examples, 790259 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:28,630 : INFO : EPOCH 6 - PROGRESS: at 7.04% examples, 815554 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:29,641 : INFO : EPOCH 6 - PROGRESS: at 10.82% examples, 824826 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:30,649 : INFO : EPOCH 6 - PROGRESS: at 14.34% examples, 819393 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:31,672 : INFO : EPOCH 6 - PROGRESS: at 18.01% examples, 818677 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:32,688 : INFO : EPOCH 6 - PROGRESS: at 21.75% examples, 821773 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:33,685 : INFO : EPOCH 6 - PROGRESS: at 25.08% examples, 814867 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:27:34,687 : INFO : EPOCH 6 - PROGRESS: at 28.61% examples, 814468 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:35,684 : INFO : EPOCH 6 - PROGRESS: at 32.43% examples, 819616 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:27:36,700 : INFO : EPOCH 6 - PROGRESS: at 36.13% examples, 821771 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:37,718 : INFO : EPOCH 6 - PROGRESS: at 39.80% examples, 823587 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:38,714 : INFO : EPOCH 6 - PROGRESS: at 43.42% examples, 824275 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:39,735 : INFO : EPOCH 6 - PROGRESS: at 47.00% examples, 822280 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:40,763 : INFO : EPOCH 6 - PROGRESS: at 50.76% examples, 823087 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:41,782 : INFO : EPOCH 6 - PROGRESS: at 54.48% examples, 824171 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:42,780 : INFO : EPOCH 6 - PROGRESS: at 58.11% examples, 824724 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:43,782 : INFO : EPOCH 6 - PROGRESS: at 61.69% examples, 824248 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:44,789 : INFO : EPOCH 6 - PROGRESS: at 65.43% examples, 825896 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:45,791 : INFO : EPOCH 6 - PROGRESS: at 69.09% examples, 825963 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:46,798 : INFO : EPOCH 6 - PROGRESS: at 72.72% examples, 826730 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:47,796 : INFO : EPOCH 6 - PROGRESS: at 76.39% examples, 826424 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:48,844 : INFO : EPOCH 6 - PROGRESS: at 80.04% examples, 826317 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:49,861 : INFO : EPOCH 6 - PROGRESS: at 83.78% examples, 826838 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:27:50,859 : INFO : EPOCH 6 - PROGRESS: at 87.40% examples, 827893 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:51,875 : INFO : EPOCH 6 - PROGRESS: at 91.15% examples, 828767 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:52,882 : INFO : EPOCH 6 - PROGRESS: at 94.79% examples, 828639 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:53,901 : INFO : EPOCH 6 - PROGRESS: at 98.07% examples, 825520 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:54,451 : INFO : EPOCH 6: training on 23279529 raw words (22951015 effective words) took 27.8s, 824916 effective words/s\n",
      "2024-05-07 16:27:55,459 : INFO : EPOCH 7 - PROGRESS: at 3.54% examples, 831415 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:56,477 : INFO : EPOCH 7 - PROGRESS: at 7.04% examples, 807084 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:57,480 : INFO : EPOCH 7 - PROGRESS: at 10.69% examples, 811378 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:58,485 : INFO : EPOCH 7 - PROGRESS: at 14.47% examples, 823540 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:27:59,511 : INFO : EPOCH 7 - PROGRESS: at 18.30% examples, 828921 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:00,531 : INFO : EPOCH 7 - PROGRESS: at 22.08% examples, 831947 words/s, in_qsize 16, out_qsize 1\n",
      "2024-05-07 16:28:01,539 : INFO : EPOCH 7 - PROGRESS: at 25.86% examples, 838076 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:02,543 : INFO : EPOCH 7 - PROGRESS: at 29.65% examples, 840403 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:03,553 : INFO : EPOCH 7 - PROGRESS: at 33.21% examples, 835569 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:04,571 : INFO : EPOCH 7 - PROGRESS: at 36.67% examples, 831194 words/s, in_qsize 16, out_qsize 1\n",
      "2024-05-07 16:28:05,577 : INFO : EPOCH 7 - PROGRESS: at 40.47% examples, 834591 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:06,594 : INFO : EPOCH 7 - PROGRESS: at 44.37% examples, 838196 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:28:07,620 : INFO : EPOCH 7 - PROGRESS: at 48.24% examples, 839495 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:28:08,626 : INFO : EPOCH 7 - PROGRESS: at 51.99% examples, 840343 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:09,651 : INFO : EPOCH 7 - PROGRESS: at 55.57% examples, 838215 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:10,671 : INFO : EPOCH 7 - PROGRESS: at 59.14% examples, 835679 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:11,668 : INFO : EPOCH 7 - PROGRESS: at 62.98% examples, 838336 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:12,668 : INFO : EPOCH 7 - PROGRESS: at 66.66% examples, 839182 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:13,678 : INFO : EPOCH 7 - PROGRESS: at 70.48% examples, 839810 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:14,704 : INFO : EPOCH 7 - PROGRESS: at 74.32% examples, 840878 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:15,718 : INFO : EPOCH 7 - PROGRESS: at 78.17% examples, 842468 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:28:16,722 : INFO : EPOCH 7 - PROGRESS: at 82.03% examples, 844356 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:17,718 : INFO : EPOCH 7 - PROGRESS: at 85.72% examples, 845061 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:18,727 : INFO : EPOCH 7 - PROGRESS: at 89.48% examples, 846472 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:19,735 : INFO : EPOCH 7 - PROGRESS: at 93.30% examples, 847111 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:20,735 : INFO : EPOCH 7 - PROGRESS: at 97.10% examples, 847975 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:28:21,467 : INFO : EPOCH 7: training on 23279529 raw words (22951015 effective words) took 27.0s, 849618 effective words/s\n",
      "2024-05-07 16:28:22,522 : INFO : EPOCH 8 - PROGRESS: at 3.66% examples, 823047 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:28:23,518 : INFO : EPOCH 8 - PROGRESS: at 7.60% examples, 859646 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:24,526 : INFO : EPOCH 8 - PROGRESS: at 11.46% examples, 865337 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:25,534 : INFO : EPOCH 8 - PROGRESS: at 15.36% examples, 866135 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:26,536 : INFO : EPOCH 8 - PROGRESS: at 19.22% examples, 868683 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:27,552 : INFO : EPOCH 8 - PROGRESS: at 23.08% examples, 870146 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:28,552 : INFO : EPOCH 8 - PROGRESS: at 26.85% examples, 871346 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:29,552 : INFO : EPOCH 8 - PROGRESS: at 30.80% examples, 873406 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:30,575 : INFO : EPOCH 8 - PROGRESS: at 34.70% examples, 872534 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:31,571 : INFO : EPOCH 8 - PROGRESS: at 38.45% examples, 873292 words/s, in_qsize 15, out_qsize 1\n",
      "2024-05-07 16:28:32,587 : INFO : EPOCH 8 - PROGRESS: at 42.39% examples, 875649 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:33,604 : INFO : EPOCH 8 - PROGRESS: at 46.38% examples, 876560 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:34,601 : INFO : EPOCH 8 - PROGRESS: at 50.25% examples, 876907 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:28:35,619 : INFO : EPOCH 8 - PROGRESS: at 54.21% examples, 877688 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:36,644 : INFO : EPOCH 8 - PROGRESS: at 58.11% examples, 878045 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:37,649 : INFO : EPOCH 8 - PROGRESS: at 62.00% examples, 878445 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:38,666 : INFO : EPOCH 8 - PROGRESS: at 65.93% examples, 879073 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:39,664 : INFO : EPOCH 8 - PROGRESS: at 69.83% examples, 879098 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:28:40,676 : INFO : EPOCH 8 - PROGRESS: at 73.75% examples, 879986 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:41,689 : INFO : EPOCH 8 - PROGRESS: at 77.62% examples, 879343 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:42,697 : INFO : EPOCH 8 - PROGRESS: at 81.51% examples, 880313 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:43,703 : INFO : EPOCH 8 - PROGRESS: at 85.24% examples, 879126 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:44,711 : INFO : EPOCH 8 - PROGRESS: at 88.92% examples, 878627 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:45,717 : INFO : EPOCH 8 - PROGRESS: at 92.68% examples, 877640 words/s, in_qsize 16, out_qsize 2\n",
      "2024-05-07 16:28:46,724 : INFO : EPOCH 8 - PROGRESS: at 96.57% examples, 878021 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:28:47,604 : INFO : EPOCH 8: training on 23279529 raw words (22951015 effective words) took 26.1s, 878345 effective words/s\n",
      "2024-05-07 16:28:48,609 : INFO : EPOCH 9 - PROGRESS: at 3.37% examples, 791388 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:49,608 : INFO : EPOCH 9 - PROGRESS: at 7.25% examples, 839649 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:50,615 : INFO : EPOCH 9 - PROGRESS: at 11.19% examples, 854109 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:51,643 : INFO : EPOCH 9 - PROGRESS: at 15.10% examples, 857043 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:52,638 : INFO : EPOCH 9 - PROGRESS: at 18.82% examples, 855372 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:28:53,645 : INFO : EPOCH 9 - PROGRESS: at 22.68% examples, 861530 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:54,643 : INFO : EPOCH 9 - PROGRESS: at 26.56% examples, 866978 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:28:55,650 : INFO : EPOCH 9 - PROGRESS: at 30.47% examples, 868289 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:28:56,656 : INFO : EPOCH 9 - PROGRESS: at 34.49% examples, 871461 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:57,666 : INFO : EPOCH 9 - PROGRESS: at 38.14% examples, 869403 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:58,678 : INFO : EPOCH 9 - PROGRESS: at 41.98% examples, 870024 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:28:59,685 : INFO : EPOCH 9 - PROGRESS: at 46.00% examples, 873227 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:00,693 : INFO : EPOCH 9 - PROGRESS: at 49.86% examples, 873040 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:01,699 : INFO : EPOCH 9 - PROGRESS: at 53.80% examples, 875001 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:02,715 : INFO : EPOCH 9 - PROGRESS: at 57.72% examples, 875965 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:03,714 : INFO : EPOCH 9 - PROGRESS: at 61.65% examples, 877144 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:04,729 : INFO : EPOCH 9 - PROGRESS: at 65.35% examples, 874786 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:05,728 : INFO : EPOCH 9 - PROGRESS: at 69.26% examples, 875455 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:06,767 : INFO : EPOCH 9 - PROGRESS: at 72.92% examples, 872461 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:07,801 : INFO : EPOCH 9 - PROGRESS: at 77.08% examples, 874120 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:08,805 : INFO : EPOCH 9 - PROGRESS: at 80.92% examples, 875033 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:09,812 : INFO : EPOCH 9 - PROGRESS: at 84.81% examples, 876053 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:10,810 : INFO : EPOCH 9 - PROGRESS: at 88.68% examples, 877354 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:11,816 : INFO : EPOCH 9 - PROGRESS: at 92.51% examples, 877479 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:12,821 : INFO : EPOCH 9 - PROGRESS: at 96.45% examples, 878137 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:13,721 : INFO : EPOCH 9: training on 23279529 raw words (22951015 effective words) took 26.1s, 878924 effective words/s\n",
      "2024-05-07 16:29:14,757 : INFO : EPOCH 10 - PROGRESS: at 3.66% examples, 832067 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:15,784 : INFO : EPOCH 10 - PROGRESS: at 7.74% examples, 867419 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:29:16,803 : INFO : EPOCH 10 - PROGRESS: at 11.81% examples, 881621 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:17,810 : INFO : EPOCH 10 - PROGRESS: at 15.93% examples, 891596 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:18,827 : INFO : EPOCH 10 - PROGRESS: at 19.98% examples, 896775 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:19,835 : INFO : EPOCH 10 - PROGRESS: at 23.95% examples, 896259 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:20,863 : INFO : EPOCH 10 - PROGRESS: at 27.92% examples, 897835 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:21,870 : INFO : EPOCH 10 - PROGRESS: at 32.05% examples, 900334 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:22,885 : INFO : EPOCH 10 - PROGRESS: at 35.90% examples, 897284 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:23,893 : INFO : EPOCH 10 - PROGRESS: at 39.80% examples, 898240 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:24,896 : INFO : EPOCH 10 - PROGRESS: at 43.72% examples, 898057 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:25,893 : INFO : EPOCH 10 - PROGRESS: at 47.76% examples, 898947 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:26,899 : INFO : EPOCH 10 - PROGRESS: at 51.74% examples, 899634 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:27,895 : INFO : EPOCH 10 - PROGRESS: at 55.65% examples, 899872 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:28,920 : INFO : EPOCH 10 - PROGRESS: at 59.72% examples, 900627 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:29,916 : INFO : EPOCH 10 - PROGRESS: at 63.64% examples, 900611 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:30,921 : INFO : EPOCH 10 - PROGRESS: at 67.63% examples, 901123 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:31,947 : INFO : EPOCH 10 - PROGRESS: at 71.70% examples, 901567 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:32,963 : INFO : EPOCH 10 - PROGRESS: at 75.80% examples, 902456 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:33,959 : INFO : EPOCH 10 - PROGRESS: at 79.73% examples, 903206 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:34,985 : INFO : EPOCH 10 - PROGRESS: at 83.70% examples, 902417 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:35,991 : INFO : EPOCH 10 - PROGRESS: at 87.65% examples, 903230 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:37,028 : INFO : EPOCH 10 - PROGRESS: at 91.66% examples, 903248 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:38,033 : INFO : EPOCH 10 - PROGRESS: at 95.77% examples, 903894 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:39,041 : INFO : EPOCH 10 - PROGRESS: at 99.77% examples, 904724 words/s, in_qsize 5, out_qsize 1\n",
      "2024-05-07 16:29:39,061 : INFO : EPOCH 10: training on 23279529 raw words (22951015 effective words) took 25.3s, 905685 effective words/s\n",
      "2024-05-07 16:29:40,066 : INFO : EPOCH 11 - PROGRESS: at 3.70% examples, 868159 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:41,069 : INFO : EPOCH 11 - PROGRESS: at 7.74% examples, 893464 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:42,087 : INFO : EPOCH 11 - PROGRESS: at 11.86% examples, 902562 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:43,094 : INFO : EPOCH 11 - PROGRESS: at 15.97% examples, 908736 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:44,098 : INFO : EPOCH 11 - PROGRESS: at 19.98% examples, 909457 words/s, in_qsize 16, out_qsize 1\n",
      "2024-05-07 16:29:45,119 : INFO : EPOCH 11 - PROGRESS: at 24.07% examples, 910297 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:46,137 : INFO : EPOCH 11 - PROGRESS: at 28.05% examples, 910997 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:47,136 : INFO : EPOCH 11 - PROGRESS: at 32.09% examples, 910604 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:48,133 : INFO : EPOCH 11 - PROGRESS: at 35.38% examples, 893580 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:49,167 : INFO : EPOCH 11 - PROGRESS: at 39.09% examples, 888333 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:50,168 : INFO : EPOCH 11 - PROGRESS: at 42.78% examples, 884564 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:51,216 : INFO : EPOCH 11 - PROGRESS: at 46.74% examples, 882573 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:52,234 : INFO : EPOCH 11 - PROGRESS: at 50.85% examples, 884906 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:29:53,230 : INFO : EPOCH 11 - PROGRESS: at 54.90% examples, 888170 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:54,242 : INFO : EPOCH 11 - PROGRESS: at 58.92% examples, 890055 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:55,260 : INFO : EPOCH 11 - PROGRESS: at 62.77% examples, 888325 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:56,258 : INFO : EPOCH 11 - PROGRESS: at 66.66% examples, 889038 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:29:57,257 : INFO : EPOCH 11 - PROGRESS: at 70.70% examples, 890198 words/s, in_qsize 15, out_qsize 1\n",
      "2024-05-07 16:29:58,274 : INFO : EPOCH 11 - PROGRESS: at 73.98% examples, 882583 words/s, in_qsize 16, out_qsize 1\n",
      "2024-05-07 16:29:59,287 : INFO : EPOCH 11 - PROGRESS: at 77.44% examples, 877331 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:00,288 : INFO : EPOCH 11 - PROGRESS: at 81.34% examples, 878742 words/s, in_qsize 14, out_qsize 0\n",
      "2024-05-07 16:30:01,286 : INFO : EPOCH 11 - PROGRESS: at 85.15% examples, 878685 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:02,307 : INFO : EPOCH 11 - PROGRESS: at 89.09% examples, 880234 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:03,304 : INFO : EPOCH 11 - PROGRESS: at 92.86% examples, 879439 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:04,321 : INFO : EPOCH 11 - PROGRESS: at 96.58% examples, 877967 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:05,283 : INFO : EPOCH 11: training on 23279529 raw words (22951015 effective words) took 26.2s, 875409 effective words/s\n",
      "2024-05-07 16:30:06,311 : INFO : EPOCH 12 - PROGRESS: at 3.66% examples, 842190 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:07,328 : INFO : EPOCH 12 - PROGRESS: at 7.69% examples, 871376 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:08,335 : INFO : EPOCH 12 - PROGRESS: at 11.81% examples, 891599 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:09,343 : INFO : EPOCH 12 - PROGRESS: at 16.00% examples, 905092 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:10,361 : INFO : EPOCH 12 - PROGRESS: at 20.11% examples, 908447 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:11,364 : INFO : EPOCH 12 - PROGRESS: at 24.21% examples, 911260 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:12,370 : INFO : EPOCH 12 - PROGRESS: at 28.27% examples, 915686 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:13,384 : INFO : EPOCH 12 - PROGRESS: at 32.38% examples, 916539 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:14,388 : INFO : EPOCH 12 - PROGRESS: at 36.38% examples, 916648 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:15,394 : INFO : EPOCH 12 - PROGRESS: at 40.47% examples, 919130 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:16,391 : INFO : EPOCH 12 - PROGRESS: at 44.54% examples, 920184 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:17,389 : INFO : EPOCH 12 - PROGRESS: at 48.72% examples, 922506 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:18,415 : INFO : EPOCH 12 - PROGRESS: at 52.82% examples, 922513 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:19,411 : INFO : EPOCH 12 - PROGRESS: at 56.92% examples, 923727 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:20,422 : INFO : EPOCH 12 - PROGRESS: at 60.96% examples, 923729 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:21,420 : INFO : EPOCH 12 - PROGRESS: at 65.13% examples, 925354 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:22,434 : INFO : EPOCH 12 - PROGRESS: at 69.30% examples, 926169 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:23,438 : INFO : EPOCH 12 - PROGRESS: at 73.35% examples, 926557 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:24,455 : INFO : EPOCH 12 - PROGRESS: at 77.54% examples, 926369 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:25,467 : INFO : EPOCH 12 - PROGRESS: at 81.56% examples, 926292 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:26,482 : INFO : EPOCH 12 - PROGRESS: at 85.67% examples, 927365 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:27,484 : INFO : EPOCH 12 - PROGRESS: at 89.69% examples, 927696 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:28,497 : INFO : EPOCH 12 - PROGRESS: at 93.79% examples, 927620 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:29,505 : INFO : EPOCH 12 - PROGRESS: at 97.86% examples, 927667 words/s, in_qsize 16, out_qsize 1\n",
      "2024-05-07 16:30:30,003 : INFO : EPOCH 12: training on 23279529 raw words (22951015 effective words) took 24.7s, 928543 effective words/s\n",
      "2024-05-07 16:30:31,011 : INFO : EPOCH 13 - PROGRESS: at 3.94% examples, 927774 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:32,018 : INFO : EPOCH 13 - PROGRESS: at 7.74% examples, 890801 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:33,025 : INFO : EPOCH 13 - PROGRESS: at 11.95% examples, 911187 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:34,038 : INFO : EPOCH 13 - PROGRESS: at 16.10% examples, 916367 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:35,032 : INFO : EPOCH 13 - PROGRESS: at 20.29% examples, 924493 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:36,055 : INFO : EPOCH 13 - PROGRESS: at 24.48% examples, 928157 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:37,056 : INFO : EPOCH 13 - PROGRESS: at 28.53% examples, 928855 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:38,064 : INFO : EPOCH 13 - PROGRESS: at 32.82% examples, 933176 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:39,082 : INFO : EPOCH 13 - PROGRESS: at 36.98% examples, 934401 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:40,088 : INFO : EPOCH 13 - PROGRESS: at 41.01% examples, 934136 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:41,096 : INFO : EPOCH 13 - PROGRESS: at 45.27% examples, 936655 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:42,098 : INFO : EPOCH 13 - PROGRESS: at 49.45% examples, 937384 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:43,126 : INFO : EPOCH 13 - PROGRESS: at 53.54% examples, 935373 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:44,132 : INFO : EPOCH 13 - PROGRESS: at 57.72% examples, 936850 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:45,150 : INFO : EPOCH 13 - PROGRESS: at 61.87% examples, 936701 words/s, in_qsize 15, out_qsize 1\n",
      "2024-05-07 16:30:46,154 : INFO : EPOCH 13 - PROGRESS: at 65.86% examples, 934910 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:47,175 : INFO : EPOCH 13 - PROGRESS: at 69.95% examples, 933628 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:48,173 : INFO : EPOCH 13 - PROGRESS: at 74.11% examples, 934920 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:49,177 : INFO : EPOCH 13 - PROGRESS: at 78.25% examples, 935531 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:50,195 : INFO : EPOCH 13 - PROGRESS: at 82.39% examples, 935608 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:51,199 : INFO : EPOCH 13 - PROGRESS: at 86.46% examples, 936161 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:52,207 : INFO : EPOCH 13 - PROGRESS: at 90.66% examples, 937308 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:53,213 : INFO : EPOCH 13 - PROGRESS: at 94.71% examples, 936793 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:54,211 : INFO : EPOCH 13 - PROGRESS: at 98.76% examples, 936517 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:54,491 : INFO : EPOCH 13: training on 23279529 raw words (22951015 effective words) took 24.5s, 937515 effective words/s\n",
      "2024-05-07 16:30:55,544 : INFO : EPOCH 14 - PROGRESS: at 3.98% examples, 896118 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:30:56,540 : INFO : EPOCH 14 - PROGRESS: at 8.30% examples, 935871 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:30:57,562 : INFO : EPOCH 14 - PROGRESS: at 12.51% examples, 937395 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:58,561 : INFO : EPOCH 14 - PROGRESS: at 16.82% examples, 946451 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:30:59,580 : INFO : EPOCH 14 - PROGRESS: at 20.96% examples, 944156 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:00,596 : INFO : EPOCH 14 - PROGRESS: at 25.08% examples, 943316 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:01,594 : INFO : EPOCH 14 - PROGRESS: at 29.29% examples, 946235 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:02,606 : INFO : EPOCH 14 - PROGRESS: at 33.29% examples, 939916 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:03,604 : INFO : EPOCH 14 - PROGRESS: at 37.49% examples, 942635 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:04,614 : INFO : EPOCH 14 - PROGRESS: at 41.53% examples, 941823 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:05,609 : INFO : EPOCH 14 - PROGRESS: at 45.78% examples, 944265 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:31:06,615 : INFO : EPOCH 14 - PROGRESS: at 49.99% examples, 944914 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:07,621 : INFO : EPOCH 14 - PROGRESS: at 54.12% examples, 944496 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:08,637 : INFO : EPOCH 14 - PROGRESS: at 58.11% examples, 941665 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:09,644 : INFO : EPOCH 14 - PROGRESS: at 62.40% examples, 943663 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:10,642 : INFO : EPOCH 14 - PROGRESS: at 66.50% examples, 944081 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:11,658 : INFO : EPOCH 14 - PROGRESS: at 70.75% examples, 944058 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:31:12,658 : INFO : EPOCH 14 - PROGRESS: at 75.03% examples, 945913 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:13,664 : INFO : EPOCH 14 - PROGRESS: at 79.09% examples, 945443 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:31:14,672 : INFO : EPOCH 14 - PROGRESS: at 82.99% examples, 943016 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:15,692 : INFO : EPOCH 14 - PROGRESS: at 86.67% examples, 938320 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:16,690 : INFO : EPOCH 14 - PROGRESS: at 90.62% examples, 936768 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:17,697 : INFO : EPOCH 14 - PROGRESS: at 94.84% examples, 937841 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:18,711 : INFO : EPOCH 14 - PROGRESS: at 99.00% examples, 938570 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:31:18,921 : INFO : EPOCH 14: training on 23279529 raw words (22951015 effective words) took 24.4s, 939497 effective words/s\n",
      "2024-05-07 16:31:19,937 : INFO : EPOCH 15 - PROGRESS: at 3.83% examples, 891794 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:20,955 : INFO : EPOCH 15 - PROGRESS: at 8.05% examples, 918315 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:31:21,959 : INFO : EPOCH 15 - PROGRESS: at 12.20% examples, 925898 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:22,967 : INFO : EPOCH 15 - PROGRESS: at 16.35% examples, 927653 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:23,971 : INFO : EPOCH 15 - PROGRESS: at 20.49% examples, 931529 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:24,995 : INFO : EPOCH 15 - PROGRESS: at 24.85% examples, 937583 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:26,003 : INFO : EPOCH 15 - PROGRESS: at 29.01% examples, 941820 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:27,000 : INFO : EPOCH 15 - PROGRESS: at 33.33% examples, 945119 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:28,013 : INFO : EPOCH 15 - PROGRESS: at 37.49% examples, 945170 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:29,025 : INFO : EPOCH 15 - PROGRESS: at 41.60% examples, 945760 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:30,059 : INFO : EPOCH 15 - PROGRESS: at 45.91% examples, 945802 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:31,063 : INFO : EPOCH 15 - PROGRESS: at 50.17% examples, 947197 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:31:32,070 : INFO : EPOCH 15 - PROGRESS: at 54.35% examples, 947911 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:33,088 : INFO : EPOCH 15 - PROGRESS: at 58.63% examples, 949040 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:34,092 : INFO : EPOCH 15 - PROGRESS: at 62.81% examples, 949074 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:31:35,094 : INFO : EPOCH 15 - PROGRESS: at 67.15% examples, 952034 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:36,110 : INFO : EPOCH 15 - PROGRESS: at 71.28% examples, 950731 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:31:37,105 : INFO : EPOCH 15 - PROGRESS: at 75.56% examples, 951673 words/s, in_qsize 14, out_qsize 2\n",
      "2024-05-07 16:31:38,113 : INFO : EPOCH 15 - PROGRESS: at 79.69% examples, 952319 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:39,111 : INFO : EPOCH 15 - PROGRESS: at 83.82% examples, 951905 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:40,135 : INFO : EPOCH 15 - PROGRESS: at 87.99% examples, 952364 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:41,139 : INFO : EPOCH 15 - PROGRESS: at 92.21% examples, 953064 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:42,156 : INFO : EPOCH 15 - PROGRESS: at 96.23% examples, 951191 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:43,032 : INFO : EPOCH 15: training on 23279529 raw words (22951015 effective words) took 24.1s, 952289 effective words/s\n",
      "2024-05-07 16:31:44,056 : INFO : EPOCH 16 - PROGRESS: at 3.98% examples, 914104 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:45,070 : INFO : EPOCH 16 - PROGRESS: at 8.38% examples, 948415 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:46,095 : INFO : EPOCH 16 - PROGRESS: at 12.77% examples, 957064 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:47,102 : INFO : EPOCH 16 - PROGRESS: at 17.02% examples, 957660 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:31:48,108 : INFO : EPOCH 16 - PROGRESS: at 21.13% examples, 954018 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:49,103 : INFO : EPOCH 16 - PROGRESS: at 25.25% examples, 953171 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:50,113 : INFO : EPOCH 16 - PROGRESS: at 28.93% examples, 937475 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:51,121 : INFO : EPOCH 16 - PROGRESS: at 32.96% examples, 932720 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:52,134 : INFO : EPOCH 16 - PROGRESS: at 36.76% examples, 925127 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:31:53,140 : INFO : EPOCH 16 - PROGRESS: at 41.01% examples, 931079 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:54,146 : INFO : EPOCH 16 - PROGRESS: at 45.23% examples, 933115 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:55,154 : INFO : EPOCH 16 - PROGRESS: at 49.54% examples, 936680 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:56,170 : INFO : EPOCH 16 - PROGRESS: at 53.84% examples, 939100 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:57,187 : INFO : EPOCH 16 - PROGRESS: at 58.16% examples, 941420 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:58,203 : INFO : EPOCH 16 - PROGRESS: at 62.47% examples, 943543 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:31:59,214 : INFO : EPOCH 16 - PROGRESS: at 66.58% examples, 943579 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:00,222 : INFO : EPOCH 16 - PROGRESS: at 70.95% examples, 945534 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:01,230 : INFO : EPOCH 16 - PROGRESS: at 75.17% examples, 946112 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:02,230 : INFO : EPOCH 16 - PROGRESS: at 79.33% examples, 947225 words/s, in_qsize 15, out_qsize 1\n",
      "2024-05-07 16:32:03,237 : INFO : EPOCH 16 - PROGRESS: at 83.65% examples, 948957 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:04,245 : INFO : EPOCH 16 - PROGRESS: at 87.78% examples, 949686 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:32:05,261 : INFO : EPOCH 16 - PROGRESS: at 91.97% examples, 950047 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:06,269 : INFO : EPOCH 16 - PROGRESS: at 96.33% examples, 951573 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:07,110 : INFO : EPOCH 16: training on 23279529 raw words (22951015 effective words) took 24.1s, 953015 effective words/s\n",
      "2024-05-07 16:32:08,137 : INFO : EPOCH 17 - PROGRESS: at 3.98% examples, 919400 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:09,172 : INFO : EPOCH 17 - PROGRESS: at 8.42% examples, 947694 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:10,190 : INFO : EPOCH 17 - PROGRESS: at 12.85% examples, 961708 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:11,207 : INFO : EPOCH 17 - PROGRESS: at 17.07% examples, 955935 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:12,224 : INFO : EPOCH 17 - PROGRESS: at 21.32% examples, 956781 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:13,222 : INFO : EPOCH 17 - PROGRESS: at 25.41% examples, 954563 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:32:14,249 : INFO : EPOCH 17 - PROGRESS: at 29.68% examples, 955172 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:15,257 : INFO : EPOCH 17 - PROGRESS: at 34.08% examples, 959124 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:32:16,257 : INFO : EPOCH 17 - PROGRESS: at 38.33% examples, 962253 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:17,270 : INFO : EPOCH 17 - PROGRESS: at 42.52% examples, 962033 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:18,287 : INFO : EPOCH 17 - PROGRESS: at 46.91% examples, 963318 words/s, in_qsize 16, out_qsize 1\n",
      "2024-05-07 16:32:19,292 : INFO : EPOCH 17 - PROGRESS: at 51.23% examples, 964596 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:20,289 : INFO : EPOCH 17 - PROGRESS: at 55.52% examples, 966390 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:21,295 : INFO : EPOCH 17 - PROGRESS: at 59.75% examples, 966322 words/s, in_qsize 16, out_qsize 1\n",
      "2024-05-07 16:32:22,302 : INFO : EPOCH 17 - PROGRESS: at 64.11% examples, 967636 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:32:23,319 : INFO : EPOCH 17 - PROGRESS: at 68.39% examples, 967410 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:24,358 : INFO : EPOCH 17 - PROGRESS: at 72.76% examples, 967822 words/s, in_qsize 14, out_qsize 1\n",
      "2024-05-07 16:32:25,363 : INFO : EPOCH 17 - PROGRESS: at 77.23% examples, 969433 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:26,370 : INFO : EPOCH 17 - PROGRESS: at 81.36% examples, 968447 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:27,376 : INFO : EPOCH 17 - PROGRESS: at 85.60% examples, 969138 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:28,391 : INFO : EPOCH 17 - PROGRESS: at 89.78% examples, 968828 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:32:29,396 : INFO : EPOCH 17 - PROGRESS: at 94.10% examples, 969563 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:32:30,424 : INFO : EPOCH 17 - PROGRESS: at 98.33% examples, 968558 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:30,869 : INFO : EPOCH 17: training on 23279529 raw words (22951015 effective words) took 23.8s, 966325 effective words/s\n",
      "2024-05-07 16:32:31,891 : INFO : EPOCH 18 - PROGRESS: at 3.32% examples, 771213 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:32,923 : INFO : EPOCH 18 - PROGRESS: at 6.87% examples, 780413 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:33,936 : INFO : EPOCH 18 - PROGRESS: at 10.98% examples, 823599 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:34,945 : INFO : EPOCH 18 - PROGRESS: at 15.36% examples, 863031 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:35,961 : INFO : EPOCH 18 - PROGRESS: at 19.57% examples, 881622 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:36,977 : INFO : EPOCH 18 - PROGRESS: at 23.86% examples, 894972 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:37,998 : INFO : EPOCH 18 - PROGRESS: at 28.06% examples, 903100 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:39,006 : INFO : EPOCH 18 - PROGRESS: at 32.43% examples, 913048 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:32:40,010 : INFO : EPOCH 18 - PROGRESS: at 36.55% examples, 917082 words/s, in_qsize 16, out_qsize 1\n",
      "2024-05-07 16:32:41,008 : INFO : EPOCH 18 - PROGRESS: at 40.76% examples, 923056 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:32:42,006 : INFO : EPOCH 18 - PROGRESS: at 44.93% examples, 925469 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:43,009 : INFO : EPOCH 18 - PROGRESS: at 49.20% examples, 928829 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:44,016 : INFO : EPOCH 18 - PROGRESS: at 53.42% examples, 931183 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:45,026 : INFO : EPOCH 18 - PROGRESS: at 57.67% examples, 934086 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:46,032 : INFO : EPOCH 18 - PROGRESS: at 61.65% examples, 932255 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:47,031 : INFO : EPOCH 18 - PROGRESS: at 65.89% examples, 934608 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:48,040 : INFO : EPOCH 18 - PROGRESS: at 70.11% examples, 935865 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:32:49,059 : INFO : EPOCH 18 - PROGRESS: at 74.41% examples, 937359 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:50,067 : INFO : EPOCH 18 - PROGRESS: at 78.66% examples, 939448 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:51,065 : INFO : EPOCH 18 - PROGRESS: at 82.83% examples, 940280 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:52,073 : INFO : EPOCH 18 - PROGRESS: at 86.97% examples, 941418 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:53,069 : INFO : EPOCH 18 - PROGRESS: at 91.16% examples, 942412 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:32:54,080 : INFO : EPOCH 18 - PROGRESS: at 95.40% examples, 943334 words/s, in_qsize 16, out_qsize 1\n",
      "2024-05-07 16:32:55,087 : INFO : EPOCH 18 - PROGRESS: at 99.62% examples, 944474 words/s, in_qsize 9, out_qsize 0\n",
      "2024-05-07 16:32:55,158 : INFO : EPOCH 18: training on 23279529 raw words (22951015 effective words) took 24.3s, 945077 effective words/s\n",
      "2024-05-07 16:32:56,193 : INFO : EPOCH 19 - PROGRESS: at 3.98% examples, 910018 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:57,204 : INFO : EPOCH 19 - PROGRESS: at 8.38% examples, 950510 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:32:58,212 : INFO : EPOCH 19 - PROGRESS: at 12.64% examples, 952154 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:32:59,230 : INFO : EPOCH 19 - PROGRESS: at 16.94% examples, 955035 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:33:00,237 : INFO : EPOCH 19 - PROGRESS: at 21.13% examples, 954078 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:33:01,245 : INFO : EPOCH 19 - PROGRESS: at 25.29% examples, 954783 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:33:02,254 : INFO : EPOCH 19 - PROGRESS: at 29.60% examples, 957675 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:33:03,263 : INFO : EPOCH 19 - PROGRESS: at 33.95% examples, 959539 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:33:04,269 : INFO : EPOCH 19 - PROGRESS: at 38.05% examples, 958203 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:33:05,305 : INFO : EPOCH 19 - PROGRESS: at 42.35% examples, 959101 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:33:06,316 : INFO : EPOCH 19 - PROGRESS: at 46.74% examples, 961820 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:33:07,314 : INFO : EPOCH 19 - PROGRESS: at 50.89% examples, 959770 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:33:08,358 : INFO : EPOCH 19 - PROGRESS: at 55.27% examples, 960558 words/s, in_qsize 16, out_qsize 1\n",
      "2024-05-07 16:33:09,378 : INFO : EPOCH 19 - PROGRESS: at 59.67% examples, 962299 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:33:10,387 : INFO : EPOCH 19 - PROGRESS: at 63.94% examples, 962603 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:33:11,414 : INFO : EPOCH 19 - PROGRESS: at 68.31% examples, 963439 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:33:12,432 : INFO : EPOCH 19 - PROGRESS: at 72.60% examples, 963935 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:33:13,441 : INFO : EPOCH 19 - PROGRESS: at 76.91% examples, 963731 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:33:14,440 : INFO : EPOCH 19 - PROGRESS: at 81.05% examples, 963827 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:33:15,459 : INFO : EPOCH 19 - PROGRESS: at 85.28% examples, 963447 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:33:16,465 : INFO : EPOCH 19 - PROGRESS: at 89.48% examples, 964490 words/s, in_qsize 15, out_qsize 0\n",
      "2024-05-07 16:33:17,474 : INFO : EPOCH 19 - PROGRESS: at 93.70% examples, 964170 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:33:18,481 : INFO : EPOCH 19 - PROGRESS: at 97.99% examples, 964710 words/s, in_qsize 16, out_qsize 0\n",
      "2024-05-07 16:33:18,969 : INFO : EPOCH 19: training on 23279529 raw words (22951015 effective words) took 23.8s, 964070 effective words/s\n",
      "2024-05-07 16:33:18,969 : INFO : Doc2Vec lifecycle event {'msg': 'training on 465590580 raw words (459020300 effective words) took 532.1s, 862690 effective words/s', 'datetime': '2024-05-07T16:33:18.969786', 'gensim': '4.3.2', 'python': '3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.22631-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Doc2Vec<dm/c,d100,n5,w5,mc2,t8>\n",
      "\n",
      "0.299760 Doc2Vec<dm/c,d100,n5,w5,mc2,t8>\n",
      "\n",
      "\n",
      "Evaluating Doc2Vec<dbow,d100,n5,mc2,t8>+Doc2Vec<dm/m,d100,n5,w10,mc2,t8>\n",
      "\n",
      "0.10328 Doc2Vec<dbow,d100,n5,mc2,t8>+Doc2Vec<dm/m,d100,n5,w10,mc2,t8>\n",
      "\n",
      "\n",
      "Evaluating Doc2Vec<dbow,d100,n5,mc2,t8>+Doc2Vec<dm/c,d100,n5,w5,mc2,t8>\n",
      "\n",
      "0.10552 Doc2Vec<dbow,d100,n5,mc2,t8>+Doc2Vec<dm/c,d100,n5,w5,mc2,t8>\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieved Sentiment-Prediction Accuracy\n--------------------------------------\nCompare error rates achieved, best-to-worst\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:35:03.580116Z",
     "start_time": "2024-05-07T14:35:03.574081Z"
    }
   },
   "source": [
    "print(\"Err_rate Model\")\nfor rate, name in sorted((rate, name) for name, rate in error_rates.items()):\n    print(f\"{rate} {name}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err_rate Model\n",
      "0.10328 Doc2Vec<dbow,d100,n5,mc2,t8>+Doc2Vec<dm/m,d100,n5,w10,mc2,t8>\n",
      "0.10408 Doc2Vec<dbow,d100,n5,mc2,t8>\n",
      "0.10552 Doc2Vec<dbow,d100,n5,mc2,t8>+Doc2Vec<dm/c,d100,n5,w5,mc2,t8>\n",
      "0.16976 Doc2Vec<dm/m,d100,n5,w10,mc2,t8>\n",
      "0.29976 Doc2Vec<dm/c,d100,n5,w5,mc2,t8>\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our testing, contrary to the results of the paper, on this problem,\nPV-DBOW alone performs as good as anything else. Concatenating vectors from\ndifferent models only sometimes offers a tiny predictive improvement – and\nstays generally close to the best-performing solo model included.\n\nThe best results achieved here are just around 10% error rate, still a long\nway from the paper's reported 7.42% error rate.\n\n(Other trials not shown, with larger vectors and other changes, also don't\ncome close to the paper's reported value. Others around the net have reported\na similar inability to reproduce the paper's best numbers. The PV-DM/C mode\nimproves a bit with many more training epochs – but doesn't reach parity with\nPV-DBOW.)\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining Results\n-----------------\n\nLet's look for answers to the following questions:\n\n#. Are inferred vectors close to the precalculated ones?\n#. Do close documents seem more related than distant ones?\n#. Do the word vectors show useful similarities?\n#. Are the word vectors from this dataset any good at analogies?\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are inferred vectors close to the precalculated ones?\n-----------------------------------------------------\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:39:36.018542Z",
     "start_time": "2024-05-07T14:39:35.989523Z"
    }
   },
   "source": [
    "doc_id = np.random.randint(len(simple_models[0].dv))  # Pick random doc; re-run cell for more examples\nprint(f'for doc {doc_id}...')\nfor model in simple_models:\n    inferred_docvec = model.infer_vector(alldocs[doc_id].words)\n    print(f'{model}:\\n {model.dv.most_similar([inferred_docvec], topn=3)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for doc 40253...\n",
      "Doc2Vec<dbow,d100,n5,mc2,t8>:\n",
      " [(40253, 0.9738572835922241), (44693, 0.6579931378364563), (42498, 0.6414970755577087)]\n",
      "Doc2Vec<dm/m,d100,n5,w10,mc2,t8>:\n",
      " [(40253, 0.9069275259971619), (53282, 0.665367066860199), (43539, 0.663693368434906)]\n",
      "Doc2Vec<dm/c,d100,n5,w5,mc2,t8>:\n",
      " [(40253, 0.6365260481834412), (3844, 0.502201497554779), (57826, 0.4490082859992981)]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Yes, here the stored vector from 20 epochs of training is usually one of the\nclosest to a freshly-inferred vector for the same words. Defaults for\ninference may benefit from tuning for each dataset or model parameters.)\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do close documents seem more related than distant ones?\n-------------------------------------------------------\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:43:44.286897Z",
     "start_time": "2024-05-07T14:43:44.203044Z"
    }
   },
   "source": [
    "import random\n\ndoc_id = np.random.randint(len(simple_models[0].dv))  # pick random doc, re-run cell for more examples\nmodel = random.choice(simple_models)  # and a random model\nsims = model.dv.most_similar(doc_id, topn=len(model.dv))  # get *all* similar documents\nprint(f'TARGET ({doc_id}): «{\" \".join(alldocs[doc_id].words)}»\\n')\nprint(f'SIMILAR/DISSIMILAR DOCS PER MODEL {model}%s:\\n')\nfor label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n    s = sims[index]\n    i = sims[index][0]\n    words = ' '.join(alldocs[i].words)\n    print(f'{label} {s}: «{words}»\\n')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET (98042): «I am really amazed how bad acting can really be, I guess that is an art too... You could not make it worse with the old form of Russian synchronization in movies, where every role is spoken by one (male) person and every sentence begins with \"he sais\" or \"she sais\"... Or wait a minute, is it maybe a new form of comedy? Is there a secret award for the worst movies - this would certainly make it to the top. I still really have no clue what it is about, a bomb attack on what by who and what for and... ugh, what is the matter with all the dialogs in the movie? Even first graders have a better vocabulary. But one has to admit, it is really hard to forget such a movie and you couldn't stop watching it either because you just can't believe what you see.»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dbow,d100,n5,mc2,t8>%s:\n",
      "\n",
      "MOST (65619, 0.6676626205444336): «I can't believe that this is supposed to be made after the early 70's... I mean even a twelve year old with his home PC could do better in special effects - I will not comment on the story since there isn't any but I think you could see this movie as some kind of messed up modern art what at least would explain why it was made. So if you think you have already seen the worst movie ever - check this out !»\n",
      "\n",
      "MEDIAN (76500, 0.32780301570892334): «Trying to beat the odds in order to live a normal life is always common for certain people. In \"Mask\", Roy L.\"Rocky\" Dennis, 1961-1978(Eric Stolz) was born with craniodiaphyseal dysplasia, a rare cranial bone disease that inflated his head. lives with his biker gang mother Rusty(Cher) and family. She was wild, out of control, and very much a loving mother in the middle. She sees a smart, understanding, and determined young man under that visage. It was great when Rocky told that teen that he would \"take off his mask, until he takes off his\". It goes to shows that people with disabilities got feelings too. Rocky wanted nothing best but going to Europe, and visit the counties he wanted to go. Had a girlfriend who was blind. But everything took a dive. His friend had decided to live with his divorced father, and his girlfriend went to a blind school in another city. Rusty, his mother was a positive figure in his life. Her strong will, and big heart helped Rocky overcome the obstacles. Only his disease did him in. A strong, heart-wrenching movie, that gives meaning, you can do it! No matter what! 5 stars!»\n",
      "\n",
      "LEAST (80618, -0.03152131661772728): «I have to thank Kevin Costner for taking me West. \"Wyatt Earp\" led me to pick up a copy of the early Earp bio by Stuart Lake while working in Canada, and I was surprised to find photos of the actual historical people tipped inside. The resemblance of the actors to those they portrayed impressed me.<br /><br />I continued to research. I went to Tombstone and stayed at a nearby ranch. The town itself declined Costner's office to rebuild it with accuracy, preferring the leave things as they are (very touristy). The gunfight was actually held in the street, etc. My research matched at least striking physical/type casting for 17 characters, from major characters (the Earps and their wives/women) to the Cowboys, Beehan, Doc Holiday, his Kate, and Bat Masterson. Linden Ashby is the most striking doppelganger; indeed, he seems to be a physical reincarnation of Morgan Earp. Dennis Quaid lost some 40 pounds or so for the role of Doc Holiday and his resemblance to the TB-plagued gambler from Valdosta, Georgia is eerie as well.<br /><br />Costner caught a lot of flack for this film; in fact, few critics noted the historical sense that he achieved. Granted, some cuts are made in time frame/continuity to speed plot along (i.e. timing of attacks on Morgan and Virgil), and the film is lengthy. I learned that the Cowboy/Earp feud was not mere ill-will, but that the strife represented political differences and clashing economic interests, as well as the \"theft\" of a lover. The old diaries and biographies are fascinating! I learned that Morgan Earp told Allie Earp something like, \"I want to leave Tombstone and never come back\" moments before he was shot to death.<br /><br />Of note, Johnny Beehan's partner in the Dexter Corral in Tombstone was a man named \"John Dunbar\". This was Costner's character's name in \"Dances with Wolves\". Go figure. Read more about it! Granted Lake embellished Earp's image, but the place, the times and the issues are fascinating.»\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat, in terms of reviewer tone, movie genre, etc... the MOST\ncosine-similar docs usually seem more like the TARGET than the MEDIAN or\nLEAST... especially if the MOST has a cosine-similarity > 0.5. Re-run the\ncell to try another random target document.\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the word vectors show useful similarities?\n---------------------------------------------\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:48:35.111729Z",
     "start_time": "2024-05-07T14:48:34.915288Z"
    }
   },
   "source": [
    "import random\n\nword_models = simple_models[:]\n\ndef pick_random_word(model, threshold=10):\n    # pick a random word with a suitable number of occurences\n    while True:\n        word = random.choice(model.wv.index_to_key)\n        if model.wv.get_vecattr(word, \"count\") > threshold:\n            return word\n\ntarget_word = pick_random_word(word_models[0])\n# or uncomment below line, to just pick a word from the relevant domain:\n# target_word = 'comedy/drama'\n\nfor model in word_models:\n    print(f'target_word: {repr(target_word)} model: {model} similar words:')\n    for i, (word, sim) in enumerate(model.wv.most_similar(target_word, topn=10), 1):\n        print(f'    {i}. {sim:.2f} {repr(word)}')\n    print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_word: '3\".' model: Doc2Vec<dbow,d100,n5,mc2,t8> similar words:\n",
      "    1. 0.46 'coin?'\n",
      "    2. 0.44 'raps.'\n",
      "    3. 0.42 '\"uprising\"'\n",
      "    4. 0.41 'interest?'\n",
      "    5. 0.41 'Goat,'\n",
      "    6. 0.41 'locating'\n",
      "    7. 0.40 'Romero.'\n",
      "    8. 0.40 'Heart.'\n",
      "    9. 0.40 '\"Disco'\n",
      "    10. 0.40 'tasteful,'\n",
      "\n",
      "target_word: '3\".' model: Doc2Vec<dm/m,d100,n5,w10,mc2,t8> similar words:\n",
      "    1. 0.61 'Gigli.'\n",
      "    2. 0.60 'Versus.'\n",
      "    3. 0.60 'Lucy.'\n",
      "    4. 0.60 '2\".'\n",
      "    5. 0.59 'Summer.'\n",
      "    6. 0.59 'Out.'\n",
      "    7. 0.58 'why.'\n",
      "    8. 0.58 'Scream.'\n",
      "    9. 0.58 'Water.'\n",
      "    10. 0.58 'general!'\n",
      "\n",
      "target_word: '3\".' model: Doc2Vec<dm/c,d100,n5,w5,mc2,t8> similar words:\n",
      "    1. 0.67 '2?'\n",
      "    2. 0.66 '/>5)'\n",
      "    3. 0.65 'Break.'\n",
      "    4. 0.65 'mercenaries.'\n",
      "    5. 0.65 'Decision.'\n",
      "    6. 0.65 'A.K.A'\n",
      "    7. 0.64 'Day.\"'\n",
      "    8. 0.63 'Morgan).'\n",
      "    9. 0.63 'Fenton.'\n",
      "    10. 0.63 'of?'\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the DBOW words look meaningless? That's because the gensim DBOW model\ndoesn't train word vectors – they remain at their random initialized values –\nunless you ask with the ``dbow_words=1`` initialization parameter. Concurrent\nword-training slows DBOW mode significantly, and offers little improvement\n(and sometimes a little worsening) of the error rate on this IMDB\nsentiment-prediction task, but may be appropriate on other tasks, or if you\nalso need word-vectors.\n\nWords from DM models tend to show meaningfully similar words when there are\nmany examples in the training data (as with 'plot' or 'actor'). (All DM modes\ninherently involve word-vector training concurrent with doc-vector training.)\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the word vectors from this dataset any good at analogies?\n-------------------------------------------------------------\n\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T14:56:10.050564Z",
     "start_time": "2024-05-07T14:50:31.406137Z"
    }
   },
   "source": [
    "from gensim.test.utils import datapath\nquestions_filename = datapath('questions-words.txt')\n\n# Note: this analysis takes many minutes\nfor model in word_models:\n    score, sections = model.wv.evaluate_word_analogies(questions_filename)\n    correct, incorrect = len(sections[-1]['correct']), len(sections[-1]['incorrect'])\n    print(f'{model}: {float(correct*100)/(correct+incorrect):0.2f}%% correct ({correct} of {correct+incorrect}')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:50:31,566 : INFO : Evaluating word analogies for top 300000 words in the model on C:\\Users\\voliveira\\Documents\\00-Proyectos\\MyZone\\.venv\\Lib\\site-packages\\gensim\\test\\test_data\\questions-words.txt\n",
      "2024-05-07 16:50:35,290 : INFO : capital-common-countries: 0.0% (0/420)\n",
      "2024-05-07 16:50:42,731 : INFO : capital-world: 0.0% (0/902)\n",
      "2024-05-07 16:50:43,459 : INFO : currency: 0.0% (0/86)\n",
      "2024-05-07 16:50:55,933 : INFO : city-in-state: 0.0% (0/1510)\n",
      "2024-05-07 16:51:00,098 : INFO : family: 0.0% (0/506)\n",
      "2024-05-07 16:51:08,359 : INFO : gram1-adjective-to-adverb: 0.0% (0/992)\n",
      "2024-05-07 16:51:14,652 : INFO : gram2-opposite: 0.0% (0/756)\n",
      "2024-05-07 16:51:25,577 : INFO : gram3-comparative: 0.0% (0/1332)\n",
      "2024-05-07 16:51:34,260 : INFO : gram4-superlative: 0.0% (0/1056)\n",
      "2024-05-07 16:51:42,543 : INFO : gram5-present-participle: 0.0% (0/992)\n",
      "2024-05-07 16:51:54,576 : INFO : gram6-nationality-adjective: 0.0% (0/1445)\n",
      "2024-05-07 16:52:07,366 : INFO : gram7-past-tense: 0.0% (0/1560)\n",
      "2024-05-07 16:52:17,162 : INFO : gram8-plural: 0.0% (0/1190)\n",
      "2024-05-07 16:52:24,243 : INFO : gram9-plural-verbs: 0.0% (0/870)\n",
      "2024-05-07 16:52:24,243 : INFO : Quadruplets with out-of-vocabulary words: 30.3%\n",
      "2024-05-07 16:52:24,243 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
      "2024-05-07 16:52:24,243 : INFO : Total accuracy: 0.0% (0/13617)\n",
      "2024-05-07 16:52:24,413 : INFO : Evaluating word analogies for top 300000 words in the model on C:\\Users\\voliveira\\Documents\\00-Proyectos\\MyZone\\.venv\\Lib\\site-packages\\gensim\\test\\test_data\\questions-words.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow,d100,n5,mc2,t8>: 0.00%% correct (0 of 13617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:52:28,020 : INFO : capital-common-countries: 2.4% (10/420)\n",
      "2024-05-07 16:52:35,664 : INFO : capital-world: 0.3% (3/902)\n",
      "2024-05-07 16:52:36,401 : INFO : currency: 0.0% (0/86)\n",
      "2024-05-07 16:52:49,497 : INFO : city-in-state: 0.1% (2/1510)\n",
      "2024-05-07 16:52:53,944 : INFO : family: 39.1% (198/506)\n",
      "2024-05-07 16:53:02,034 : INFO : gram1-adjective-to-adverb: 3.8% (38/992)\n",
      "2024-05-07 16:53:08,332 : INFO : gram2-opposite: 6.6% (50/756)\n",
      "2024-05-07 16:53:20,133 : INFO : gram3-comparative: 46.8% (623/1332)\n",
      "2024-05-07 16:53:29,491 : INFO : gram4-superlative: 25.8% (272/1056)\n",
      "2024-05-07 16:53:38,009 : INFO : gram5-present-participle: 24.4% (242/992)\n",
      "2024-05-07 16:53:50,221 : INFO : gram6-nationality-adjective: 2.6% (37/1445)\n",
      "2024-05-07 16:54:03,688 : INFO : gram7-past-tense: 28.5% (445/1560)\n",
      "2024-05-07 16:54:13,969 : INFO : gram8-plural: 20.3% (242/1190)\n",
      "2024-05-07 16:54:21,055 : INFO : gram9-plural-verbs: 43.2% (376/870)\n",
      "2024-05-07 16:54:21,055 : INFO : Quadruplets with out-of-vocabulary words: 30.3%\n",
      "2024-05-07 16:54:21,055 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
      "2024-05-07 16:54:21,055 : INFO : Total accuracy: 18.6% (2538/13617)\n",
      "2024-05-07 16:54:21,231 : INFO : Evaluating word analogies for top 300000 words in the model on C:\\Users\\voliveira\\Documents\\00-Proyectos\\MyZone\\.venv\\Lib\\site-packages\\gensim\\test\\test_data\\questions-words.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dm/m,d100,n5,w10,mc2,t8>: 18.64%% correct (2538 of 13617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 16:54:24,546 : INFO : capital-common-countries: 2.6% (11/420)\n",
      "2024-05-07 16:54:31,841 : INFO : capital-world: 0.7% (6/902)\n",
      "2024-05-07 16:54:32,555 : INFO : currency: 0.0% (0/86)\n",
      "2024-05-07 16:54:44,180 : INFO : city-in-state: 0.1% (1/1510)\n",
      "2024-05-07 16:54:48,378 : INFO : family: 36.0% (182/506)\n",
      "2024-05-07 16:54:56,471 : INFO : gram1-adjective-to-adverb: 6.4% (63/992)\n",
      "2024-05-07 16:55:02,529 : INFO : gram2-opposite: 4.8% (36/756)\n",
      "2024-05-07 16:55:13,425 : INFO : gram3-comparative: 35.9% (478/1332)\n",
      "2024-05-07 16:55:21,766 : INFO : gram4-superlative: 27.9% (295/1056)\n",
      "2024-05-07 16:55:29,706 : INFO : gram5-present-participle: 35.6% (353/992)\n",
      "2024-05-07 16:55:40,862 : INFO : gram6-nationality-adjective: 1.2% (17/1445)\n",
      "2024-05-07 16:55:53,177 : INFO : gram7-past-tense: 26.7% (416/1560)\n",
      "2024-05-07 16:56:03,053 : INFO : gram8-plural: 11.8% (141/1190)\n",
      "2024-05-07 16:56:10,027 : INFO : gram9-plural-verbs: 49.5% (431/870)\n",
      "2024-05-07 16:56:10,027 : INFO : Quadruplets with out-of-vocabulary words: 30.3%\n",
      "2024-05-07 16:56:10,027 : INFO : NB: analogies containing OOV words were skipped from evaluation! To change this behavior, use \"dummy4unknown=True\"\n",
      "2024-05-07 16:56:10,027 : INFO : Total accuracy: 17.8% (2430/13617)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dm/c,d100,n5,w5,mc2,t8>: 17.85%% correct (2430 of 13617\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though this is a tiny, domain-specific dataset, it shows some meager\ncapability on the general word analogies – at least for the DM/mean and\nDM/concat models which actually train word vectors. (The untrained\nrandom-initialized words of the DBOW model of course fail miserably.)\n\n\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
